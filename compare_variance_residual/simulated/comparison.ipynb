{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup",
   "id": "8fa47ad38e950864"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T08:24:22.641532Z",
     "start_time": "2025-01-23T08:24:21.209504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from compare_variance_residual.simulated.plotting import plot_experiment\n",
    "from compare_variance_residual.simulated.simulation import run_experiment\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "plt.style.use('ggplot')"
   ],
   "id": "66100b6064c7cb11",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T08:24:22.863753Z",
     "start_time": "2025-01-23T08:24:22.649570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from himalaya.backend import set_backend\n",
    "\n",
    "backend = set_backend(\"cupy\", on_error=\"warn\")"
   ],
   "id": "e6b181500bf004db",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T08:24:22.952326Z",
     "start_time": "2025-01-23T08:24:22.947498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_results(variable_name, variable_values, overwrite=True, **variables):\n",
    "    experiment_dir = get_experiment_dir(variable_name, **variables)\n",
    "\n",
    "    variance_filename = \"variance.npy\"\n",
    "    residual_filename = \"residual.npy\"\n",
    "    variance_path = os.path.join(experiment_dir, variance_filename)\n",
    "    residual_path = os.path.join(experiment_dir, residual_filename)\n",
    "\n",
    "    if overwrite or not os.path.exists(variance_path) or not os.path.exists(residual_path):\n",
    "        if not os.path.exists(experiment_dir):\n",
    "            os.makedirs(experiment_dir)\n",
    "        predicted_variance, predicted_residual = run_experiment(variable_name, variable_values, **variables)\n",
    "        np.save(variance_path, predicted_variance)\n",
    "        np.save(residual_path, predicted_residual)\n",
    "    else:\n",
    "        predicted_variance = np.load(variance_path, allow_pickle=True)\n",
    "        predicted_residual = np.load(residual_path, allow_pickle=True)\n",
    "        # turn into python lists\n",
    "        predicted_variance = predicted_variance.tolist()\n",
    "        predicted_residual = predicted_residual.tolist()\n",
    "    return predicted_variance, predicted_residual\n",
    "\n",
    "\n",
    "def get_experiment_dir(variable_name, **variables):\n",
    "    result_dir = \"./results\"\n",
    "    experiment_variables = \"\".join(\n",
    "        ['{}={!r}'.format(k,\n",
    "                          [\n",
    "                              f\"{i:.2f}\" if isinstance(i, float) else i  # Handle floats in the list\n",
    "                              for i in v\n",
    "                          ] if isinstance(v, list)\n",
    "                          else f\"{v:.2f}\" if isinstance(v, float) else v  # Handle floats not in lists\n",
    "                          )\n",
    "         for k, v in variables.items()])\n",
    "\n",
    "    # replace illegal characters\n",
    "    experiment_variables = experiment_variables.replace(\" \", \"\")\n",
    "    experiment_variables = experiment_variables.replace(\"[\", \"\")\n",
    "    experiment_variables = experiment_variables.replace(\"]\", \"\")\n",
    "\n",
    "    # cut filename, if it is too long\n",
    "    if len(experiment_variables) > 255:\n",
    "        experiment_variables = experiment_variables[:255]\n",
    "\n",
    "    experiment_dir = os.path.join(result_dir, variable_name, experiment_variables)\n",
    "    return experiment_dir"
   ],
   "id": "d034219756ea38a2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Set default values to be used in the tests",
   "id": "31cc6cc348998e5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T08:24:22.995489Z",
     "start_time": "2025-01-23T08:24:22.993018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_observations = 3\n",
    "\n",
    "variables = dict(\n",
    "    # dataset\n",
    "    n_runs=100,\n",
    "    n_observations=n_observations,\n",
    "    d_list=[100, 100, 100],\n",
    "    scalars=[1 / 3, 1 / 3, 1 / 3],\n",
    "    n_targets=100,\n",
    "    n_samples_train=1000,\n",
    "    n_samples_test=100,\n",
    "    noise_level=0.1,\n",
    "    construction_method=\"stack\",\n",
    "    random_distribution=\"normal\",\n",
    "\n",
    "    # method parameters\n",
    "    direct_vp=False,\n",
    "    ignore_negative_r2=False,\n",
    "    use_ols=False,\n",
    "\n",
    "    # ridge regression\n",
    "    cv=5,\n",
    "    alphas=np.logspace(-4, 4, 9),\n",
    ")"
   ],
   "id": "e5876b1ce8673f11",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Varying distributions",
   "id": "efb7542759669d71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T08:24:23.044672Z",
     "start_time": "2025-01-23T08:24:23.042453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "variable_name = \"sampling distribution\"\n",
    "random_distributions = [\n",
    "    \"normal\",\n",
    "    \"uniform\",\n",
    "    \"exponential\",\n",
    "    \"gamma\",\n",
    "    \"beta\",\n",
    "    \"lognormal\",\n",
    "    \"pareto\"\n",
    "]"
   ],
   "id": "950b3ad85eaff7ae",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-23T08:24:23.090233Z"
    }
   },
   "cell_type": "code",
   "source": "predicted_variance, predicted_residual = get_results(variable_name, random_distributions, **variables)",
   "id": "b5eebeadd66db023",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] 0% | 0.00 sec | Varying sampling distribution | "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_experiment(variable_name, random_distributions, predicted_variance, predicted_residual,\n",
    "                save_dir=get_experiment_dir(variable_name, **variables), **variables)"
   ],
   "id": "6552f2710e306f80"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test varying sample sizes",
   "id": "f759794a3c1b9ee6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## varying train sample sizes",
   "id": "93122c11fb15b177"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mag = np.log10(variables[\"n_samples_train\"])\n",
    "sample_sizes_training = np.logspace(mag - 1, mag + 1, n_observations)\n",
    "variable_name = \"sample size training\""
   ],
   "id": "929cd90349da7118"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "predicted_variance, predicted_residual = get_results(variable_name, sample_sizes_training, **variables)",
   "id": "9b986dbeca81ed3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_experiment(variable_name, sample_sizes_training, predicted_variance, predicted_residual, x_is_log=True,\n",
    "                save_dir=get_experiment_dir(variable_name, **variables),\n",
    "                **variables)"
   ],
   "id": "1f5eded243155051"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## varying test sample sizes",
   "id": "f4d8d787c34a1d8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mag = np.log10(variables[\"n_samples_test\"])\n",
    "sample_sizes_testing = np.logspace(mag - 1, mag + 1, n_observations)\n",
    "variable_name = \"sample size testing\""
   ],
   "id": "7cdd690569cbd84a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "predicted_variance, predicted_residual = get_results(variable_name, sample_sizes_testing, **variables)",
   "id": "4c0578bd1dd18bf5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_experiment(variable_name, sample_sizes_testing, predicted_variance, predicted_residual, x_is_log=True,\n",
    "                save_dir=get_experiment_dir(variable_name, **variables), **variables)"
   ],
   "id": "db42e0f1f56b3e71"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test varying feature sizes",
   "id": "1332652e26851773"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mag = np.log10(variables[\"d_list\"][0])\n",
    "feature_sizes = np.logspace(mag - 1, mag + 1, n_observations)\n",
    "variable_name = \"number of features\""
   ],
   "id": "677a691754c294ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "predicted_variance, predicted_residual = get_results(variable_name, feature_sizes, **variables)",
   "id": "f846fb6a8a306d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_experiment(variable_name, feature_sizes, predicted_variance, predicted_residual, x_is_log=True,\n",
    "                save_dir=get_experiment_dir(variable_name, **variables), **variables)"
   ],
   "id": "f9db0960390c85a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# varying target size",
   "id": "f6953c97e68ef228"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "variable_name = \"number of targets\"\n",
    "mag = np.log10(variables[\"n_targets\"])\n",
    "target_sizes = np.logspace(mag - 1, mag + 1, n_observations)"
   ],
   "id": "1483a3649f0de1cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "predicted_variance, predicted_residual = get_results(variable_name, target_sizes, **variables)",
   "id": "66b3444318675200"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_experiment(variable_name, target_sizes, predicted_variance, predicted_residual, x_is_log=True,\n",
    "                save_dir=get_experiment_dir(variable_name, **variables), **variables)"
   ],
   "id": "aad453d23c7a317d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test varying noise levels",
   "id": "3cb051d5649e0334"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "variable_name = \"scalar amount of noise in the target\"\n",
    "noise_levels = np.linspace(0, 1, n_observations)"
   ],
   "id": "8d7da3086d664796"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "predicted_variance, predicted_residual = get_results(variable_name, noise_levels, **variables)",
   "id": "7d1bc861be61e8ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_experiment(variable_name, noise_levels, predicted_variance, predicted_residual,\n",
    "                save_dir=get_experiment_dir(variable_name, **variables), **variables)"
   ],
   "id": "a89cd18d602c2f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test varying unique variances of unique feature spaces",
   "id": "5a4795f9e9f52bbb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "variable_name = \"unique variance explained\"\n",
    "unique_variances = np.linspace(0, 1, n_observations)\n",
    "# convert from np to python\n",
    "unique_variances = [round(float(x), 2) for x in unique_variances]"
   ],
   "id": "15f83413274f41c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "variances = []\n",
    "for unique_variance in unique_variances:\n",
    "    remainders = (1 - unique_variance) / (len(variables[\"scalars\"]) - 1)\n",
    "    # construct arrray of arrays, where the second entry is equal to unique_variance and the rest are equal to the remainder\n",
    "    variance = [remainders] * len(variables[\"scalars\"])\n",
    "    variance[1] = unique_variance\n",
    "    variances.append(variance)\n",
    "\n",
    "predicted_variance, predicted_residual = get_results(variable_name, variances, **variables)\n",
    "plot_experiment(variable_name, variances, predicted_variance, predicted_residual,\n",
    "                save_dir=get_experiment_dir(variable_name, **variables), **variables)"
   ],
   "id": "8e4da74373f12da6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
