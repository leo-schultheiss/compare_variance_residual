{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-31T14:49:54.158772Z",
     "start_time": "2025-01-31T14:49:53.111159Z"
    }
   },
   "source": [
    "import logging\n",
    "from importlib import reload\n",
    "\n",
    "import himalaya.scoring\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from himalaya.backend import set_backend\n",
    "from matplotlib import axes\n",
    "\n",
    "from simulation import generate_dataset\n",
    "\n",
    "set_backend(\"cupy\", on_error=\"warn\")\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T14:49:54.166522Z",
     "start_time": "2025-01-31T14:49:54.162147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ],
   "id": "629fb3728ffdf57d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T14:49:54.246573Z",
     "start_time": "2025-01-31T14:49:54.242784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generic_errorbar_plot(means, variances, labels, horizontal_positions, title, suptitle, ylabel, xlabel,  n_samples_train, n_samples_test,ax: axes.Axes = None, fig=None):\n",
    "    \"\"\"Generic plot function for shared parameters between vp_errorbar and rm_errorbar.\"\"\"\n",
    "\n",
    "    if ax is None or fig is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    yerr =  [np.sqrt(var) / np.sqrt(n_samples_test) for var in variances]\n",
    "    colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\", \"tab:brown\"]\n",
    "\n",
    "    # Create bar plot\n",
    "    bars = ax.bar(range(len(means)), means, color=colors[:len(means)], yerr=yerr, capsize=5, ecolor=\"black\")\n",
    "    ax.bar_label(bars, fmt='{:,.2f}', label_type='center')\n",
    "    ax.set_xticks(range(len(means)), labels=labels)\n",
    "\n",
    "    # Function to plot horizontal lines\n",
    "    def plot_horizontal_line(start, end, y_value, label, color):\n",
    "        ax.plot([start, end], [y_value, y_value], linestyle='--', label=label, color=color)\n",
    "\n",
    "    # Plot horizontal lines\n",
    "    for i, (y_value, label, start, end) in enumerate(horizontal_positions):\n",
    "        plot_horizontal_line(start, end, y_value, label, colors[i % len(colors)])\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    ylims = ax.get_ylim()\n",
    "    ax.set_ylim(ylims[0], 1.01)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(xlabel)\n",
    "\n",
    "    fig.suptitle(suptitle)\n",
    "    ax.set_title(title)\n",
    "    return ax, fig"
   ],
   "id": "7736ae090148bf86",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T14:49:54.288599Z",
     "start_time": "2025-01-31T14:49:54.286235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_space_dimensions = [\n",
    "    100,  # shared\n",
    "    100,  # unique 0\n",
    "    100,  # unique 1\n",
    "]\n",
    "scalars = [\n",
    "0.6 , 0.3 , 0.1\n",
    "]\n",
    "n_targets = 1000\n",
    "n_samples_train = 10000\n",
    "n_samples_test = 100\n",
    "noise_scalar = 0.1\n",
    "\n",
    "cv = 20\n",
    "alphas=np.logspace(-4, 4, 20)"
   ],
   "id": "932307cb1705d75d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T14:49:55.530Z",
     "start_time": "2025-01-31T14:49:54.332869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(Xs_train, Xs_test, Y_train, Y_test) = generate_dataset(feature_space_dimensions, scalars, n_targets, n_samples_train,\n",
    "                                                        n_samples_test, noise_scalar)"
   ],
   "id": "aa2870586733128f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Variance Partitioning",
   "id": "26dd6ebe135a88f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def vp_errorbar(score_0, score_1, joint_score, shared, x0_unique, x1_unique, feature_space_dimensions, scalars,\n",
    "                n_targets, n_samples_train, n_samples_test, noise_scalar, ax: axes.Axes = None, fig=None):\n",
    "    # Precompute means and variances\n",
    "    scores = [score_0, score_1, joint_score, shared, x0_unique, x1_unique]\n",
    "    means = [s.mean() for s in scores]\n",
    "    variances = [s.var() for s in scores]\n",
    "\n",
    "    bar_names = [r\"$X_0$\", r\"$X_1$\", r\"$X_0 \\cup X_1$\", r\"$X_0 \\cap X_1$\", r\"$X_0 \\setminus X_1$\", r\"$X_1 \\setminus X_0$\"]\n",
    "\n",
    "    # Horizontal line positions\n",
    "    horizontal_positions = [\n",
    "        (scalars[0] + scalars[1], r\"$a_S + a_{U_0}$\", -0.5, 0.5),\n",
    "        (scalars[0] + scalars[2], r\"$a_S + a_{U_1}$\", 0.5, 1.5),\n",
    "        (sum(scalars), r\"$a_S + a_{U_0} + a_{U_1}$\", 1.5, 2.5),\n",
    "        (scalars[0], r\"$a_S$\", 2.5, 3.5),\n",
    "        (scalars[1], r\"$a_{U_0}$\", 3.5, 4.5),\n",
    "        (scalars[2], r\"$a_{U_1}$\", 4.5, 5.5)\n",
    "    ]\n",
    "\n",
    "    # Call the generic function\n",
    "    generic_errorbar_plot(\n",
    "        means=means,\n",
    "        variances=variances,\n",
    "        labels=bar_names,\n",
    "        horizontal_positions=horizontal_positions,\n",
    "        title=fr\"$a_S$: {scalars[0]:.2f}, $a_{{U_0}}$: {scalars[1]:.2f}, $a_{{U_1}}$: {scalars[2]:.2f}, $|S|$: {feature_space_dimensions[0]}, $|U_0|$: {feature_space_dimensions[1]}, $|U_1|$: {feature_space_dimensions[2]}, $a_E$: {noise_scalar}\",\n",
    "        suptitle=\"Variance partitioning\",\n",
    "        ylabel=r\"Average Variance Explained ($r^2$)\",\n",
    "        xlabel=\"Feature space\",\n",
    "        n_samples_test=n_samples_test,\n",
    "        n_samples_train=n_samples_train,\n",
    "        ax=ax,\n",
    "        fig=fig\n",
    "    )"
   ],
   "id": "80b9b4c8012a6f38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from variance_partitioning import variance_partitioning",
   "id": "a91dd1d8fdde375b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(score_0, score_1, joint_score, shared, x0_unique, x1_unique) = variance_partitioning(Xs_train, Xs_test, Y_train,\n",
    "                                                                                      Y_test, cv=cv, alphas=alphas, logger=logger)"
   ],
   "id": "b162c2b238084803",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vp_errorbar(score_0, score_1, joint_score, shared, x0_unique, x1_unique, feature_space_dimensions, scalars, n_targets,\n",
    "            n_samples_train, n_samples_test, noise_scalar)"
   ],
   "id": "e7f21353699b22a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Try using ols for all models",
   "id": "e897e0c933c8ded6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(score_0, score_1, joint_score, shared, x0_unique, x1_unique) = variance_partitioning(Xs_train, Xs_test, Y_train,\n",
    "                                                                                      Y_test, cv=cv, alphas=alphas, logger=logger, use_ols=True)"
   ],
   "id": "b0ef6690ab02fb39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vp_errorbar(score_0, score_1, joint_score, shared, x0_unique, x1_unique, feature_space_dimensions, scalars, n_targets,\n",
    "            n_samples_train, n_samples_test, noise_scalar)"
   ],
   "id": "20ad0c1a2899dcde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Residual Method",
   "id": "7cce74a62c46dce8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from residual import residual_method",
   "id": "1a3857211e518a48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def rm_errorbar(full_score_0, full_score_1, feature_score_0, feature_score_1, residual_score_0, residual_scores_1,\n",
    "                feature_space_dimensions, scalars,\n",
    "                n_targets, n_samples_train, n_samples_test, noise_scalar, ax: axes.Axes = None, fig=None):\n",
    "    if ax is None or fig is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    # Precompute means and variances\n",
    "    scores = [full_score_0, full_score_1, feature_score_0, feature_score_1, residual_score_0, residual_scores_1]\n",
    "    means = [s.mean() for s in scores]\n",
    "    variances = [s.var() for s in scores]\n",
    "\n",
    "    bar_names = [r\"$X_0$\", r\"$X_1$\", r\"$f(X_1) \\approx X_0$\", r\"$g(X_0) \\approx X_1$\", r\"$X_0 \\setminus X_1$\",\n",
    "                 r\"$X_1 \\setminus X_0$\"]\n",
    "\n",
    "    horizontal_positions = [\n",
    "        (scalars[0] + scalars[1], r\"$a_S + a_{U_0}$\", -0.5, 0.5),\n",
    "        (scalars[0] + scalars[2], r\"$a_S + a_{U_1}$\", 0.5, 1.5),\n",
    "        (feature_space_dimensions[0] / (feature_space_dimensions[0] + feature_space_dimensions[1]),\n",
    "         r\"$\\frac{|S|}{|U_0|+|S|}$\", 1.5, 2.5),\n",
    "        (feature_space_dimensions[0] / (feature_space_dimensions[0] + feature_space_dimensions[2]),\n",
    "         r\"$\\frac{|S|}{|U_1|+|S|}$\", 2.5, 3.5),\n",
    "        (scalars[1], r\"$a_{U_0}$\", 3.5, 4.5),\n",
    "        (scalars[2], r\"$a_{U_1}$\", 4.5, 5.5)\n",
    "    ]\n",
    "\n",
    "    # Call the generic_errorbar function with the required data and parameters\n",
    "    generic_errorbar_plot(\n",
    "        means=means,\n",
    "        variances=variances,\n",
    "        labels=bar_names,\n",
    "        horizontal_positions=horizontal_positions,\n",
    "        title=fr\"{n_targets} targets, $a_S$: {scalars[0]:.2f}, $|S|$: {feature_space_dimensions[0]}, $a_{{U_0}}$: {scalars[1]:.2f}, $|U_0|$: {feature_space_dimensions[1]}, $a_{{U_1}}$: {scalars[2]:.2f}, $|U_1|$: {feature_space_dimensions[2]}, $a_E$: {noise_scalar}\",\n",
    "        suptitle=\"Residual Method\",\n",
    "        ylabel=r\"Average Variance Explained ($r^2$)\",\n",
    "        xlabel=\"Feature space/Model\",\n",
    "        n_samples_test=n_samples_test,\n",
    "        n_samples_train=n_samples_train,\n",
    "        ax=ax,\n",
    "        fig=fig\n",
    "    )"
   ],
   "id": "9adff0ce4efd1caa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "full_score_0, full_score_1, feature_score_0, feature_score_1, residual_score_0, residual_scores_1 = residual_method(\n",
    "    Xs_train, Xs_test, Y_train, Y_test, use_ols=True, return_full_variance=True, cv=cv, score_func=himalaya.scoring.r2_score\n",
    ")"
   ],
   "id": "17464352d419a310",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rm_errorbar(full_score_0, full_score_1, feature_score_0, feature_score_1, residual_score_0, residual_scores_1,\n",
    "            feature_space_dimensions, scalars,\n",
    "            n_targets, n_samples_train, n_samples_test, noise_scalar)"
   ],
   "id": "743a6737a874e959",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dimensions",
   "id": "c98c82ad2b2e1db4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(12, 12), sharey='row')\n",
    "\n",
    "for i, shared_dimension in enumerate([10, 100, 1000]):\n",
    "    dimensions = feature_space_dimensions.copy()\n",
    "    dimensions[0] = shared_dimension\n",
    "\n",
    "    _n_samples_train = 2 * sum(dimensions)\n",
    "\n",
    "    (Xs_train, Xs_test, Y_train, Y_test) = generate_dataset(dimensions, scalars, n_targets, _n_samples_train,\n",
    "                                                            n_samples_test, noise_scalar)\n",
    "    (score_0, score_1, joint_score, shared, x0_unique, x1_unique) = variance_partitioning(Xs_train, Xs_test, Y_train,\n",
    "                                                                                          Y_test, cv=cv)\n",
    "    vp_errorbar(score_0, score_1, joint_score, shared, x0_unique, x1_unique, dimensions, scalars, n_targets,\n",
    "                _n_samples_train, n_samples_test, noise_scalar, ax=axs[i, 0], fig=fig)\n",
    "    axs[i, 0].set_title(f\"Variance Partitioning (Shared Dim: {shared_dimension})\")\n",
    "\n",
    "    (full_score_0, full_score_1, feature_score_0, feature_score_1, residual_score_0,\n",
    "     residual_scores_1) = residual_method(\n",
    "        Xs_train, Xs_test, Y_train, Y_test, use_ols=True, return_full_variance=True, cv=cv)\n",
    "\n",
    "    rm_errorbar(full_score_0, full_score_1, feature_score_0, feature_score_1, residual_score_0, residual_scores_1,\n",
    "                dimensions, scalars, n_targets, _n_samples_train, n_samples_test, noise_scalar, ax=axs[i, 1], fig=fig)\n",
    "    axs[i, 1].set_title(f\"Residual Method (Shared Dim: {shared_dimension})\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "3c0e2030e7ac606a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Scalars",
   "id": "7e1f2d2391373c18"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Updated code to put each plot into the subplot axes, with scalars along the rows and vp and rm in the columns\n",
    "n_scalars = 5\n",
    "fig, axs = plt.subplots(n_scalars, 2, figsize=(12, n_scalars * 4), sharey='row')  # Adjust figure size dynamically\n",
    "\n",
    "for i, shared_scalar in enumerate(np.linspace(0, 1, n_scalars)):\n",
    "    _scalars = [shared_scalar, (1 - shared_scalar) / 2, (1 - shared_scalar) / 2]\n",
    "    (Xs_train, Xs_test, Y_train, Y_test) = generate_dataset(feature_space_dimensions, _scalars, n_targets,\n",
    "                                                            n_samples_train, n_samples_test, noise_scalar)\n",
    "    (score_0, score_1, joint_score, shared, x0_unique, x1_unique) = variance_partitioning(Xs_train, Xs_test, Y_train,\n",
    "                                                                                          Y_test, cv=cv,\n",
    "                                                                                          score_func=himalaya.scoring.r2_score)\n",
    "    # Variance Partitioning subplot\n",
    "    vp_errorbar(score_0, score_1, joint_score, shared, x0_unique, x1_unique, feature_space_dimensions, _scalars,\n",
    "                n_targets, n_samples_train, n_samples_test, noise_scalar, ax=axs[i, 0], fig=fig)\n",
    "    axs[i, 0].set_title(f\"Variance Partitioning (Shared scalar: {shared_scalar:.2f})\")\n",
    "\n",
    "    # Residual Method subplot\n",
    "    full_score_0, full_score_1, feature_score_0, feature_score_1, residual_score_0, residual_scores_1 = residual_method(\n",
    "        Xs_train, Xs_test, Y_train, Y_test, use_ols=True, return_full_variance=True, cv=cv,\n",
    "        score_func=himalaya.scoring.r2_score)\n",
    "\n",
    "    rm_errorbar(full_score_0, full_score_1, feature_score_0, feature_score_1, residual_score_0, residual_scores_1,\n",
    "                feature_space_dimensions, _scalars, n_targets, n_samples_train, n_samples_test, noise_scalar,\n",
    "                ax=axs[i, 1], fig=fig)\n",
    "    axs[i, 1].set_title(f\"Residual Method (Shared scalar: {shared_scalar:.2f})\")\n",
    "\n",
    "plt.tight_layout()  # To avoid overlap of subplots\n",
    "plt.show()"
   ],
   "id": "8878b99ac8566ebf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "cca5dac3a2e29378",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
