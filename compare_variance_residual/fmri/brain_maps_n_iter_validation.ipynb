{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T20:36:34.220818Z",
     "start_time": "2025-02-26T20:36:33.971344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import himalaya.scoring\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from himalaya.backend import set_backend\n",
    "from himalaya.ridge import BandedRidgeCV, ColumnTransformerNoStack\n",
    "from matplotlib import pyplot as plt\n",
    "import simplstyles\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from voxelwise_tutorials.delayer import Delayer\n",
    "\n",
    "from fmri.features import load_brain_data, load_feature"
   ],
   "id": "bfff375e5309c59f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T20:36:35.845290Z",
     "start_time": "2025-02-26T20:36:34.225780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "backend = set_backend(\"torch_cuda\", on_error='throw')\n",
    "plt.style.use('nord-light-talk')\n",
    "data_dir = \"../../data\"\n",
    "simplstyles"
   ],
   "id": "9f527bdf0fb89006",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'simplstyles' from '/home/leo/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/simplstyles/__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T20:36:35.951290Z",
     "start_time": "2025-02-26T20:36:35.949247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "subject = 1\n",
    "modality = \"reading\""
   ],
   "id": "72617e2abcd86445",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T20:36:35.957966Z",
     "start_time": "2025-02-26T20:36:35.956095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_alphas_batch = 3\n",
    "n_targets_batch = 100\n",
    "n_targets_batch_refit = 50"
   ],
   "id": "36f8dff93992152c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T20:36:35.999924Z",
     "start_time": "2025-02-26T20:36:35.997778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "number_of_delays = 4\n",
    "alphas = np.logspace(-5, 20, 10)\n",
    "cv = 5"
   ],
   "id": "609247230299f1a0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T20:36:36.046549Z",
     "start_time": "2025-02-26T20:36:36.044134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def result_path(subject, modality, ridge_type, param_name, param_range):\n",
    "    dir = f\"results/brain_maps_validation_curves/{modality}/{subject}/{ridge_type}\"\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    path = os.path.join(dir, f\"{param_name}_{param_range}.csv\")\n",
    "    return path"
   ],
   "id": "e6e5296666b80981",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load features",
   "id": "48a87412e9034f76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T20:36:36.323755Z",
     "start_time": "2025-02-26T20:36:36.090591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_semantic, n_samples_train = load_feature(data_dir, \"english1000\")\n",
    "X_low_level, n_samples_train = load_feature(data_dir, \"letters\")\n",
    "X = np.concatenate([X_semantic, X_low_level], axis=1)"
   ],
   "id": "8eca69ca747aee30",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load brain data",
   "id": "8cc08748c05f2306"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T20:36:51.931457Z",
     "start_time": "2025-02-26T20:36:36.330349Z"
    }
   },
   "cell_type": "code",
   "source": "Y, n_samples_train = load_brain_data(data_dir, subject, modality)",
   "id": "91f2aae5f1e602d1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/PycharmProjects/compare_variance_residual/compare_variance_residual/fmri/features.py:16: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/home/leo/PycharmProjects/compare_variance_residual/compare_variance_residual/fmri/features.py:16: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/home/leo/PycharmProjects/compare_variance_residual/compare_variance_residual/fmri/features.py:16: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/home/leo/PycharmProjects/compare_variance_residual/compare_variance_residual/fmri/features.py:16: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/home/leo/PycharmProjects/compare_variance_residual/compare_variance_residual/fmri/features.py:16: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/home/leo/PycharmProjects/compare_variance_residual/compare_variance_residual/fmri/features.py:16: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/home/leo/PycharmProjects/compare_variance_residual/compare_variance_residual/fmri/features.py:16: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/home/leo/PycharmProjects/compare_variance_residual/compare_variance_residual/fmri/features.py:16: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/home/leo/PycharmProjects/compare_variance_residual/compare_variance_residual/fmri/features.py:16: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/home/leo/PycharmProjects/compare_variance_residual/compare_variance_residual/fmri/features.py:16: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/home/leo/PycharmProjects/compare_variance_residual/compare_variance_residual/fmri/features.py:18: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_test = [np.vstack([zscore(Y_test[story][i][:-trim]) for story in Y_test.keys()]) for i in range(2)]\n",
      "/home/leo/PycharmProjects/compare_variance_residual/compare_variance_residual/fmri/features.py:18: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_test = [np.vstack([zscore(Y_test[story][i][:-trim]) for story in Y_test.keys()]) for i in range(2)]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Iterations",
   "id": "fe8ba9b564464d47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T20:36:51.941408Z",
     "start_time": "2025-02-26T20:36:51.938253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_iter_range = np.linspace(1, 100, 10).astype(int)\n",
    "# turn to python ints\n",
    "n_iter_range = [int(n_iter) for n_iter in n_iter_range]\n",
    "n_iter_range"
   ],
   "id": "923ffdbe716a1c0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 12, 23, 34, 45, 56, 67, 78, 89, 100]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T20:38:12.223935Z",
     "start_time": "2025-02-26T20:36:51.985066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "cv_scores = pd.DataFrame()\n",
    "for _n_iter in n_iter_range:\n",
    "    print(_n_iter)\n",
    "    path = result_path(subject, modality, \"banded_ridge\", \"n_iter\", _n_iter)\n",
    "    if not os.path.exists(path):\n",
    "        print(\"File does not exist\")\n",
    "        delayer = Delayer(delays=range(1, number_of_delays + 1))\n",
    "        start_and_end = np.concatenate([[0], np.cumsum([X_semantic.shape[1], X_low_level.shape[1]])])\n",
    "        slices = [slice(start, end) for start, end in zip(start_and_end[:-1], start_and_end[1:])]\n",
    "        ct = ColumnTransformerNoStack(transformers=[(f'feature_{i}', delayer, s) for i, s in enumerate(slices)])\n",
    "\n",
    "        solver_params = dict(\n",
    "            alphas=alphas, n_iter=_n_iter, n_targets_batch=n_targets_batch,\n",
    "            n_alphas_batch=n_alphas_batch, n_targets_batch_refit=n_targets_batch_refit,\n",
    "            score_func=himalaya.scoring.r2_score)\n",
    "        banded_ridge_cv = BandedRidgeCV(cv=cv, groups=\"input\", solver_params=solver_params)\n",
    "\n",
    "        pipeline = make_pipeline(\n",
    "            ct,\n",
    "            banded_ridge_cv\n",
    "        )\n",
    "\n",
    "        pipeline.fit(X[:n_samples_train], Y[:n_samples_train])\n",
    "\n",
    "\n",
    "\n",
    "        prediction = pipeline.predict(X[n_samples_train:])\n",
    "        prediction = backend.to_numpy(prediction)\n",
    "\n",
    "        correlation = np.array([np.corrcoef(Y[n_samples_train:, i], prediction[:, i])[0, 1] for i in range(Y.shape[1])])\n",
    "\n",
    "        # (n_iter, n_targets)\n",
    "        cv_score = pipeline[-1].cv_scores_\n",
    "        cv_score = max(cv_score, key=lambda x: x.mean())\n",
    "\n",
    "        r2 = himalaya.scoring.r2_score(Y[n_samples_train:], prediction)\n",
    "        result = pd.DataFrame(\n",
    "            {\n",
    "                'correlation_score': correlation,\n",
    "                'cv_score': cv_score,\n",
    "                'r2_score': r2\n",
    "            }\n",
    "        )\n",
    "\n",
    "        result.to_csv(path)\n",
    "    else:\n",
    "        print(\"File exists\")\n",
    "        result = pd.read_csv(path)"
   ],
   "id": "874628fdd3c59d37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "File does not exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/home/leo/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] 0% | 0.00 sec | 1 random sampling with cv | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/himalaya/ridge/_random_search.py:140: UserWarning: Solving banded ridge is slower than solving multiple-kernel ridge when n_samples < n_features (here 3887 < 4044). Using linear kernels in himalaya.kernel_ridge.MultipleKernelRidgeCV or himalaya.kernel_ridge.solve_multiple_kernel_ridge_random_search would be faster. Use warn=False to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[........................................] 100% | 74.60 sec | 1 random sampling with cv | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3045: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/home/leo/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3046: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 39\u001B[0m\n\u001B[1;32m     36\u001B[0m     cv_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(cv_score, key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: x\u001B[38;5;241m.\u001B[39mmean())\n\u001B[1;32m     38\u001B[0m     r2 \u001B[38;5;241m=\u001B[39m himalaya\u001B[38;5;241m.\u001B[39mscoring\u001B[38;5;241m.\u001B[39mr2_score(Y[n_samples_train:], prediction)\n\u001B[0;32m---> 39\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcorrelation_score\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mcorrelation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcv_score\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mr2_score\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mr2\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m     result\u001B[38;5;241m.\u001B[39mto_csv(path)\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/pandas/core/frame.py:778\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[0;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[1;32m    772\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_mgr(\n\u001B[1;32m    773\u001B[0m         data, axes\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m\"\u001B[39m: index, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: columns}, dtype\u001B[38;5;241m=\u001B[39mdtype, copy\u001B[38;5;241m=\u001B[39mcopy\n\u001B[1;32m    774\u001B[0m     )\n\u001B[1;32m    776\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m    777\u001B[0m     \u001B[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001B[39;00m\n\u001B[0;32m--> 778\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[43mdict_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmanager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    779\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ma\u001B[38;5;241m.\u001B[39mMaskedArray):\n\u001B[1;32m    780\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mma\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m mrecords\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/pandas/core/internals/construction.py:503\u001B[0m, in \u001B[0;36mdict_to_mgr\u001B[0;34m(data, index, columns, dtype, typ, copy)\u001B[0m\n\u001B[1;32m    499\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    500\u001B[0m         \u001B[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001B[39;00m\n\u001B[1;32m    501\u001B[0m         arrays \u001B[38;5;241m=\u001B[39m [x\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m arrays]\n\u001B[0;32m--> 503\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marrays_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtyp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconsolidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/pandas/core/internals/construction.py:119\u001B[0m, in \u001B[0;36marrays_to_mgr\u001B[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001B[0m\n\u001B[1;32m    116\u001B[0m         index \u001B[38;5;241m=\u001B[39m ensure_index(index)\n\u001B[1;32m    118\u001B[0m     \u001B[38;5;66;03m# don't force copy because getting jammed in an ndarray anyway\u001B[39;00m\n\u001B[0;32m--> 119\u001B[0m     arrays, refs \u001B[38;5;241m=\u001B[39m \u001B[43m_homogenize\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;66;03m# _homogenize ensures\u001B[39;00m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m#  - all(len(x) == len(index) for x in arrays)\u001B[39;00m\n\u001B[1;32m    122\u001B[0m     \u001B[38;5;66;03m#  - all(x.ndim == 1 for x in arrays)\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    125\u001B[0m \n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    127\u001B[0m     index \u001B[38;5;241m=\u001B[39m ensure_index(index)\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/pandas/core/internals/construction.py:629\u001B[0m, in \u001B[0;36m_homogenize\u001B[0;34m(data, index, dtype)\u001B[0m\n\u001B[1;32m    626\u001B[0m         val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(val)\n\u001B[1;32m    627\u001B[0m     val \u001B[38;5;241m=\u001B[39m lib\u001B[38;5;241m.\u001B[39mfast_multiget(val, oindex\u001B[38;5;241m.\u001B[39m_values, default\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mnan)\n\u001B[0;32m--> 629\u001B[0m val \u001B[38;5;241m=\u001B[39m \u001B[43msanitize_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    630\u001B[0m com\u001B[38;5;241m.\u001B[39mrequire_length_match(val, index)\n\u001B[1;32m    631\u001B[0m refs\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/pandas/core/construction.py:630\u001B[0m, in \u001B[0;36msanitize_array\u001B[0;34m(data, index, dtype, copy, allow_2d)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(data, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__array__\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;66;03m# e.g. dask array GH#38645\u001B[39;00m\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m copy:\n\u001B[0;32m--> 630\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    631\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    632\u001B[0m         data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(data, copy\u001B[38;5;241m=\u001B[39mcopy)\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/torch/_tensor.py:1194\u001B[0m, in \u001B[0;36mTensor.__array__\u001B[0;34m(self, dtype)\u001B[0m\n\u001B[1;32m   1192\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(Tensor\u001B[38;5;241m.\u001B[39m__array__, (\u001B[38;5;28mself\u001B[39m,), \u001B[38;5;28mself\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m   1193\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1196\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mTypeError\u001B[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sns.catplot(data=cv_scores, kind='box')",
   "id": "4fc5e1dc0136a785",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
