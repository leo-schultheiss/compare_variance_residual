{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T18:28:32.553205Z",
     "start_time": "2025-02-22T18:28:32.095458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import simplstyles\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import voxelwise_tutorials.viz as viz\n",
    "from himalaya.backend import set_backend\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from compare_variance_residual.plot_noise_levels import vp_scores"
   ],
   "id": "b5dc9c4e71fd8255",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T18:28:32.563903Z",
     "start_time": "2025-02-22T18:28:32.560835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_result_path(modality, subject):\n",
    "    path = os.path.join(\"results\", modality, f\"subject{subject:02}\")\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    return path"
   ],
   "id": "e974193db6e9033a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T18:28:32.691735Z",
     "start_time": "2025-02-22T18:28:32.688507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.style.use('nord-light-talk')\n",
    "data_dir = \"../data\"\n",
    "backend = set_backend('numpy', on_error='warn')"
   ],
   "id": "4865fc9191590ff5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T18:28:32.735648Z",
     "start_time": "2025-02-22T18:28:32.733131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "language_model = \"bert-base\"\n",
    "layer = 9\n",
    "num_layers = 12\n",
    "feature = \"semantic\"\n",
    "modality = \"reading\"\n",
    "subject = 1\n",
    "low_level_feature = \"letters\"\n",
    "trim = 5  # remove 5 TRs from the start and end of each story\n",
    "sequence_length = 20\n",
    "number_of_delays = 4"
   ],
   "id": "75f6b6cc5a72a947",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T18:28:32.790206Z",
     "start_time": "2025-02-22T18:28:32.787579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "alphas = np.logspace(-5, 5, 10)\n",
    "cv = 10"
   ],
   "id": "6fa8a056a5f60f05",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Features",
   "id": "9a8914d9d0cdb926"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Low Level Feature",
   "id": "d0cd231fefc1774f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T18:28:32.843577Z",
     "start_time": "2025-02-22T18:28:32.837259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import h5py\n",
    "\n",
    "low_level_train = h5py.File(os.path.join(data_dir, 'features', 'features_trn_NEW.hdf'), 'r')\n",
    "low_level_val = h5py.File(os.path.join(data_dir, 'features', 'features_val_NEW.hdf'), 'r')\n",
    "print(low_level_train['story_01'].keys())\n",
    "print(low_level_val.keys())"
   ],
   "id": "e761e64fd154e7e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['english1000', 'letters', 'numletters', 'numphonemes', 'numwords', 'pauses', 'phonemes', 'word_length_std']>\n",
      "<KeysViewHDF5 ['story_11']>\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T18:28:32.913757Z",
     "start_time": "2025-02-22T18:28:32.893072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "low_level_train = np.vstack(\n",
    "    [zscore(low_level_train[story][low_level_feature]) for story in low_level_train.keys()])\n",
    "low_level_val = np.vstack(\n",
    "    [zscore(low_level_val[story][low_level_feature]) for story in low_level_val.keys()])\n",
    "low_level_train, low_level_val = np.nan_to_num(low_level_train), np.nan_to_num(low_level_val)\n",
    "print(low_level_train.shape, low_level_val.shape)"
   ],
   "id": "dbc1a7e7f96a875a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3887, 26) (306, 26)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load High Level (NLP) Features",
   "id": "5ba918368c5f7de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T18:28:33.639407Z",
     "start_time": "2025-02-22T18:28:32.948665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "downsampled_embeddings = np.load(f\"../{language_model}{sequence_length}_downsampled.npy\", allow_pickle=True)\n",
    "print(downsampled_embeddings.item().keys())"
   ],
   "id": "506e1dec58eb16d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['alternateithicatom', 'avatar', 'howtodraw', 'legacy', 'life', 'myfirstdaywiththeyankees', 'naked', 'odetostepfather', 'souls', 'undertheinfluence', 'wheretheressmoke'])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T18:35:53.854673Z",
     "start_time": "2025-02-22T18:35:53.806017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Rstories = ['alternateithicatom', 'avatar', 'howtodraw', 'legacy',\n",
    "            'life', 'myfirstdaywiththeyankees', 'naked',\n",
    "            'odetostepfather', 'souls', 'undertheinfluence']\n",
    "Pstories = ['wheretheressmoke']\n",
    "\n",
    "semantic_embeddings_train = np.vstack([zscore(downsampled_embeddings.item()[story][layer]) for story in Rstories])\n",
    "semantic_embeddings_val = np.vstack([zscore(downsampled_embeddings.item()[story][layer]) for story in Pstories])\n",
    "semantic_embeddings_train, semantic_embeddings_val = np.nan_to_num(semantic_embeddings_train), np.nan_to_num(\n",
    "    semantic_embeddings_val)\n",
    "print(semantic_embeddings_train.shape, semantic_embeddings_val.shape)"
   ],
   "id": "3d85bea9cacd735b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3887, 768) (306, 768)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Brain Data",
   "id": "21566d9ac985f3c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T18:28:47.167075Z",
     "start_time": "2025-02-22T18:28:33.845691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from voxelwise_tutorials.io import load_hdf5_array\n",
    "\n",
    "Y_train_filename = os.path.join(data_dir, 'responses', f'subject{subject:02}_{modality}_fmri_data_trn.hdf')\n",
    "Y_train = load_hdf5_array(Y_train_filename)\n",
    "\n",
    "Y_test_filename = os.path.join(data_dir, 'responses', f'subject{subject:02}_{modality}_fmri_data_val.hdf')\n",
    "Y_test = load_hdf5_array(Y_test_filename)\n",
    "\n",
    "Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
    "Ys_test = [np.vstack([zscore(Y_test[story][i][:-trim]) for story in Y_test.keys()]) for i in range(2)]\n",
    "\n",
    "print(Y_train.shape, Ys_test[1].shape)\n",
    "Y_train, Ys_test = np.nan_to_num(Y_train), np.nan_to_num(Ys_test)"
   ],
   "id": "c03613f2231ff7e4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50023/4107143807.py:9: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_50023/4107143807.py:9: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_50023/4107143807.py:9: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_50023/4107143807.py:9: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_50023/4107143807.py:9: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_50023/4107143807.py:9: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_50023/4107143807.py:9: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_50023/4107143807.py:9: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_50023/4107143807.py:9: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_50023/4107143807.py:9: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_50023/4107143807.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Ys_test = [np.vstack([zscore(Y_test[story][i][:-trim]) for story in Y_test.keys()]) for i in range(2)]\n",
      "/tmp/ipykernel_50023/4107143807.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Ys_test = [np.vstack([zscore(Y_test[story][i][:-trim]) for story in Y_test.keys()]) for i in range(2)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3887, 81133) (306, 81133)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Variance Partitioning",
   "id": "3451b505f2a885bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Low Level Prediction",
   "id": "e2d6bc50614f533f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T18:49:53.506943Z",
     "start_time": "2025-02-22T18:49:53.504761Z"
    }
   },
   "cell_type": "code",
   "source": "low_level_file = os.path.join(get_result_path(modality, subject), f\"vp_low_level_{low_level_feature}_scores.npy\")",
   "id": "a1dfaf45fce88d69",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T18:56:43.510820Z",
     "start_time": "2025-02-22T18:56:43.505046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from himalaya.ridge import RidgeCV\n",
    "from voxelwise_tutorials.delayer import Delayer\n",
    "\n",
    "if not os.path.exists(low_level_file):\n",
    "    print(f\"Saving {low_level_file}\")\n",
    "    # delay stimuli to account for hemodynamic lag\n",
    "    delays = range(1, number_of_delays + 1)\n",
    "\n",
    "    # fit bootstrapped ridge regression model\n",
    "    delayer = Delayer(delays=delays)\n",
    "    pipeline = make_pipeline(\n",
    "        delayer,\n",
    "        RidgeCV(\n",
    "            alphas=alphas, cv=cv,\n",
    "            solver_params=dict(n_targets_batch=50, n_alphas_batch=1, n_targets_batch_refit=50)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    pipeline.fit(low_level_train, Y_train)\n",
    "    vp_low_level_scores = []\n",
    "    for Y_test in Ys_test:\n",
    "        vp_low_level_scores.append(pipeline.score(low_level_val, Y_test))\n",
    "    vp_low_level_scores = np.array(vp_low_level_scores)\n",
    "    np.save(low_level_file, vp_low_level_scores)\n",
    "else:\n",
    "    print(f\"Loading {low_level_file}\")\n",
    "    vp_low_level_scores = np.load(low_level_file, allow_pickle=True)\n",
    "print(vp_low_level_scores.max(), vp_low_level_scores.min(), vp_low_level_scores.mean())"
   ],
   "id": "138a40d0f43fa082",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results/reading/subject01/vp_low_level_letters_scores.npy\n",
      "0.32454274791842685 -0.06318248609217014 0.002321666677206003\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Semantic Prediction",
   "id": "826c08588e853c04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T18:49:00.259163Z",
     "start_time": "2025-02-22T18:49:00.256897Z"
    }
   },
   "cell_type": "code",
   "source": "semantic_file = os.path.join(get_result_path(modality, subject), f\"vp_semantic_{layer:02}_scores.npy\")",
   "id": "df7bc2b066892f3d",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T18:56:34.434246Z",
     "start_time": "2025-02-22T18:56:34.428902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from himalaya.ridge import RidgeCV\n",
    "from voxelwise_tutorials.delayer import Delayer\n",
    "\n",
    "if not os.path.exists(semantic_file):\n",
    "    print(f\"Saving {semantic_file}\")\n",
    "    # delay stimuli to account for hemodynamic lag\n",
    "    delays = range(1, number_of_delays + 1)\n",
    "\n",
    "    # fit bootstrapped ridge regression model\n",
    "    delayer = Delayer(delays=delays)\n",
    "    pipeline = make_pipeline(\n",
    "        delayer,\n",
    "        RidgeCV(\n",
    "            alphas=alphas, cv=cv,\n",
    "            solver_params=dict(n_targets_batch=50, n_alphas_batch=1, n_targets_batch_refit=50)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    pipeline.fit(semantic_embeddings_train, Y_train)\n",
    "    vp_semantic_scores = []\n",
    "    for Y_test in Ys_test:\n",
    "        vp_semantic_scores.append(pipeline.score(semantic_embeddings_val, Y_test))\n",
    "    vp_semantic_scores = np.array(vp_semantic_scores)\n",
    "    np.save(semantic_file, vp_semantic_scores)\n",
    "else:\n",
    "    print(f\"Loading {semantic_file}\")\n",
    "    vp_semantic_scores = np.load(semantic_file, allow_pickle=True)\n",
    "print(vp_semantic_scores.max(), vp_semantic_scores.min(), vp_semantic_scores.mean())"
   ],
   "id": "93c3deb381460802",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results/reading/subject01/vp_semantic_09_scores.npy\n",
      "0.3457906230440486 -0.1617008729669207 0.0023683850304021437\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Joint Prediction",
   "id": "14b7f17e56130ec2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T18:56:52.239470Z",
     "start_time": "2025-02-22T18:56:52.237066Z"
    }
   },
   "cell_type": "code",
   "source": "joint_file = os.path.join(get_result_path(modality, subject), f\"vp_joint_{feature}_{low_level_feature}_scores.npy\")",
   "id": "8b67cb6f4d181f54",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T18:56:54.517315Z",
     "start_time": "2025-02-22T18:56:54.370798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from himalaya.ridge import GroupRidgeCV\n",
    "\n",
    "if not os.path.exists(joint_file):\n",
    "    print(f\"Saving {joint_file}\")\n",
    "    # delay stimuli to account for hemodynamic lag\n",
    "    delays = range(1, number_of_delays + 1)\n",
    "\n",
    "    # fit bootstrapped ridge regression model\n",
    "    delayer = Delayer(delays=delays)\n",
    "    pipeline = make_pipeline(\n",
    "        delayer,\n",
    "        GroupRidgeCV(\n",
    "            cv=cv, groups=\"input\",\n",
    "            solver_params=dict(alphas=alphas, n_targets_batch=50, n_alphas_batch=1, n_targets_batch_refit=50)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    pipeline.fit([semantic_embeddings_train, low_level_train], Y_train)\n",
    "    vp_joint_scores = []\n",
    "    for Y_test in Ys_test:\n",
    "        vp_joint_scores.append(pipeline.score([semantic_embeddings_val, low_level_val], Y_test))\n",
    "    vp_joint_scores = np.array(vp_joint_scores)\n",
    "    np.save(joint_file, vp_joint_scores)\n",
    "else:\n",
    "    print(f\"Loading {joint_file}\")\n",
    "    vp_joint_scores = np.load(joint_file, allow_pickle=True)"
   ],
   "id": "a98b775b1dd1f680",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results/reading/subject01/vp_joint_semantic_letters_scores.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 3887) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 18\u001B[0m\n\u001B[1;32m      9\u001B[0m delayer \u001B[38;5;241m=\u001B[39m Delayer(delays\u001B[38;5;241m=\u001B[39mdelays)\n\u001B[1;32m     10\u001B[0m pipeline \u001B[38;5;241m=\u001B[39m make_pipeline(\n\u001B[1;32m     11\u001B[0m     delayer,\n\u001B[1;32m     12\u001B[0m     GroupRidgeCV(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     15\u001B[0m     )\n\u001B[1;32m     16\u001B[0m )\n\u001B[0;32m---> 18\u001B[0m \u001B[43mpipeline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43msemantic_embeddings_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlow_level_train\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m vp_joint_scores \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m Y_test \u001B[38;5;129;01min\u001B[39;00m Ys_test:\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/sklearn/base.py:1389\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1382\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1384\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1385\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1386\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1387\u001B[0m     )\n\u001B[1;32m   1388\u001B[0m ):\n\u001B[0;32m-> 1389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:654\u001B[0m, in \u001B[0;36mPipeline.fit\u001B[0;34m(self, X, y, **params)\u001B[0m\n\u001B[1;32m    647\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    648\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe `transform_input` parameter can only be set if metadata \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    649\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrouting is enabled. You can enable metadata routing using \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    650\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`sklearn.set_config(enable_metadata_routing=True)`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    651\u001B[0m     )\n\u001B[1;32m    653\u001B[0m routed_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_method_params(method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit\u001B[39m\u001B[38;5;124m\"\u001B[39m, props\u001B[38;5;241m=\u001B[39mparams)\n\u001B[0;32m--> 654\u001B[0m Xt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mraw_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    655\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _print_elapsed_time(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeline\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log_message(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m)):\n\u001B[1;32m    656\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:588\u001B[0m, in \u001B[0;36mPipeline._fit\u001B[0;34m(self, X, y, routed_params, raw_params)\u001B[0m\n\u001B[1;32m    581\u001B[0m \u001B[38;5;66;03m# Fit or load from cache the current transformer\u001B[39;00m\n\u001B[1;32m    582\u001B[0m step_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_metadata_for_step(\n\u001B[1;32m    583\u001B[0m     step_idx\u001B[38;5;241m=\u001B[39mstep_idx,\n\u001B[1;32m    584\u001B[0m     step_params\u001B[38;5;241m=\u001B[39mrouted_params[name],\n\u001B[1;32m    585\u001B[0m     all_params\u001B[38;5;241m=\u001B[39mraw_params,\n\u001B[1;32m    586\u001B[0m )\n\u001B[0;32m--> 588\u001B[0m X, fitted_transformer \u001B[38;5;241m=\u001B[39m \u001B[43mfit_transform_one_cached\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    589\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcloned_transformer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    590\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    592\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    593\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessage_clsname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPipeline\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    594\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_log_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep_idx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    595\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstep_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    596\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    597\u001B[0m \u001B[38;5;66;03m# Replace the transformer of the step with the fitted\u001B[39;00m\n\u001B[1;32m    598\u001B[0m \u001B[38;5;66;03m# transformer. This is necessary when loading the transformer\u001B[39;00m\n\u001B[1;32m    599\u001B[0m \u001B[38;5;66;03m# from the cache.\u001B[39;00m\n\u001B[1;32m    600\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[step_idx] \u001B[38;5;241m=\u001B[39m (name, fitted_transformer)\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/joblib/memory.py:312\u001B[0m, in \u001B[0;36mNotMemorizedFunc.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 312\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1551\u001B[0m, in \u001B[0;36m_fit_transform_one\u001B[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001B[0m\n\u001B[1;32m   1549\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _print_elapsed_time(message_clsname, message):\n\u001B[1;32m   1550\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(transformer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit_transform\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1551\u001B[0m         res \u001B[38;5;241m=\u001B[39m \u001B[43mtransformer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfit_transform\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1552\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1553\u001B[0m         res \u001B[38;5;241m=\u001B[39m transformer\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit\u001B[39m\u001B[38;5;124m\"\u001B[39m, {}))\u001B[38;5;241m.\u001B[39mtransform(\n\u001B[1;32m   1554\u001B[0m             X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransform\u001B[39m\u001B[38;5;124m\"\u001B[39m, {})\n\u001B[1;32m   1555\u001B[0m         )\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py:319\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 319\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    320\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    321\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[1;32m    322\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    323\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    324\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[1;32m    325\u001B[0m         )\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/sklearn/base.py:921\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m    918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[1;32m    919\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    920\u001B[0m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[0;32m--> 921\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/voxelwise_tutorials/delayer.py:53\u001B[0m, in \u001B[0;36mDelayer.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m     39\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Fit the delayer.\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \n\u001B[1;32m     41\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;124;03m    self : returns an instance of self.\u001B[39;00m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 53\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnumeric\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_ \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/sklearn/base.py:480\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    473\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_validate_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    474\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    475\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    476\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124min 1.7. Use `sklearn.utils.validation.validate_data` instead. This \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    477\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunction becomes public and is part of the scikit-learn developer API.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    478\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    479\u001B[0m     )\n\u001B[0;32m--> 480\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mvalidate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2944\u001B[0m, in \u001B[0;36mvalidate_data\u001B[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[0m\n\u001B[1;32m   2942\u001B[0m         out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m   2943\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[0;32m-> 2944\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2945\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n\u001B[1;32m   2946\u001B[0m     out \u001B[38;5;241m=\u001B[39m _check_y(y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1055\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m   1053\u001B[0m         array \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mastype(array, dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   1054\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1055\u001B[0m         array \u001B[38;5;241m=\u001B[39m \u001B[43m_asarray_with_order\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1056\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[1;32m   1057\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1058\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[1;32m   1059\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mcomplex_warning\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:839\u001B[0m, in \u001B[0;36m_asarray_with_order\u001B[0;34m(array, dtype, order, copy, xp, device)\u001B[0m\n\u001B[1;32m    837\u001B[0m     array \u001B[38;5;241m=\u001B[39m numpy\u001B[38;5;241m.\u001B[39marray(array, order\u001B[38;5;241m=\u001B[39morder, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m    838\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 839\u001B[0m     array \u001B[38;5;241m=\u001B[39m \u001B[43mnumpy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    841\u001B[0m \u001B[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001B[39;00m\n\u001B[1;32m    842\u001B[0m \u001B[38;5;66;03m# container that is consistent with the input's namespace.\u001B[39;00m\n\u001B[1;32m    843\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m xp\u001B[38;5;241m.\u001B[39masarray(array)\n",
      "\u001B[0;31mValueError\u001B[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 3887) + inhomogeneous part."
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Residual Method",
   "id": "4c7615c170ab5a2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T17:35:40.783839937Z",
     "start_time": "2025-02-22T12:44:29.865447Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2c51f150e6695d95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plot Brain Maps",
   "id": "954bdd603b46c57d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T17:35:40.784066799Z",
     "start_time": "2025-02-22T12:44:29.908764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_flatmap_from_mapper(voxels, mapper_file, ax=None, alpha=0.7, cmap=plt.get_cmap(), vmin=None, vmax=None,\n",
    "                             with_curvature=True, with_rois=True, with_colorbar=True,\n",
    "                             colorbar_location=(.4, .9, .2, .05)):\n",
    "    \"\"\"Plot a flatmap from a mapper file, with 1D data.\n",
    "\n",
    "    This function is equivalent to the pycortex functions:\n",
    "    cortex.quickshow(cortex.Volume(voxels, ...), ...)\n",
    "\n",
    "    Note that this function does not have the full capability of pycortex,\n",
    "    since it is based on flatmap mappers and not on the original brain\n",
    "    surface of the subject.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    voxels : array of shape (n_voxels, )\n",
    "        Data to be plotted.\n",
    "    mapper_file : str\n",
    "        File name of the mapper.\n",
    "    ax : matplotlib Axes or None.\n",
    "        Axes where the figure will be plotted.\n",
    "        If None, a new figure is created.\n",
    "    alpha : float in [0, 1], or array of shape (n_voxels, )\n",
    "        Transparency of the flatmap.\n",
    "    cmap : str\n",
    "        Name of the matplotlib colormap.\n",
    "    vmin : float or None\n",
    "        Minimum value of the colormap. If None, use the 1st percentile of the\n",
    "        `voxels` array.\n",
    "    vmax : float or None\n",
    "        Minimum value of the colormap. If None, use the 99th percentile of the\n",
    "        `voxels` array.\n",
    "    with_curvature : bool\n",
    "        If True, show the curvature below the data layer.\n",
    "    with_rois : bool\n",
    "        If True, show the ROIs labels above the data layer.\n",
    "    colorbar_location : [left, bottom, width, height]\n",
    "        Location of the colorbar. All quantities are in fractions of figure\n",
    "        width and height.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ax : matplotlib Axes\n",
    "        Axes where the figure has been plotted.\n",
    "    \"\"\"\n",
    "    # create a figure\n",
    "    if ax is None:\n",
    "        flatmap_mask = load_hdf5_array(mapper_file, key='flatmap_mask')\n",
    "        figsize = np.array(flatmap_mask.shape) / 100.\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_axes((0, 0, 1, 1))\n",
    "        ax.axis('off')\n",
    "\n",
    "    # process plotting parameters\n",
    "    vmin = np.percentile(voxels, 1) if vmin is None else vmin\n",
    "    vmax = np.percentile(voxels, 99) if vmax is None else vmax\n",
    "    if isinstance(alpha, np.ndarray):\n",
    "        alpha = viz.map_voxels_to_flatmap(alpha, mapper_file)\n",
    "\n",
    "    # plot the data\n",
    "    image = viz.map_voxels_to_flatmap(voxels, mapper_file)\n",
    "    cimg = ax.imshow(image, aspect='equal', zorder=1, alpha=alpha, cmap=cmap,\n",
    "                     vmin=vmin, vmax=vmax)\n",
    "\n",
    "    if with_colorbar:\n",
    "        try:\n",
    "            cbar = ax.inset_axes(colorbar_location)\n",
    "        except AttributeError:  # for matplotlib < 3.0\n",
    "            cbar = ax.figure.add_axes(colorbar_location)\n",
    "        colorbar = ax.figure.colorbar(cimg, cax=cbar, orientation='horizontal')\n",
    "        colorbar.ax.set_title(\"Pearson Correlation of Y_true and Y_pred\", fontsize=14)\n",
    "\n",
    "    # plot additional layers if present\n",
    "    viz._plot_addition_layers(ax=ax, n_voxels=voxels.shape[0],\n",
    "                              mapper_file=mapper_file,\n",
    "                              with_curvature=with_curvature, with_rois=with_rois)\n",
    "\n",
    "    return ax"
   ],
   "id": "31138f1d9ccc8738",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T17:35:40.784194052Z",
     "start_time": "2025-02-22T12:44:42.214281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = get_path(language_model, feature, modality, subject, low_level_feature, layer)\n",
    "correlation = np.nan_to_num(np.load(path, allow_pickle=True))\n",
    "mapper_path = os.path.join(\"../data\", 'mappers', f\"subject{subject:02}_mappers.hdf\")\n",
    "flatmap_mask = load_hdf5_array(mapper_path, key='flatmap_mask')"
   ],
   "id": "e415d17fbe50326e",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/bert-base/semantic/reading/subject01/letters/layer9'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m path \u001B[38;5;241m=\u001B[39m get_path(language_model, feature, modality, subject, low_level_feature, layer)\n\u001B[0;32m----> 2\u001B[0m correlation \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mnan_to_num(\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_pickle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m)\n\u001B[1;32m      3\u001B[0m mapper_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmappers\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msubject\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msubject\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m02\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_mappers.hdf\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m flatmap_mask \u001B[38;5;241m=\u001B[39m load_hdf5_array(mapper_path, key\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mflatmap_mask\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:451\u001B[0m, in \u001B[0;36mload\u001B[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[0m\n\u001B[1;32m    449\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 451\u001B[0m     fid \u001B[38;5;241m=\u001B[39m stack\u001B[38;5;241m.\u001B[39menter_context(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    452\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    454\u001B[0m \u001B[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001B[39;00m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'results/bert-base/semantic/reading/subject01/letters/layer9'"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "figsize = np.array(flatmap_mask.shape) / 100.\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_axes((0, 0, 1, 1))\n",
    "ax.axis('off')\n",
    "plot_flatmap_from_mapper(correlation, mapper_path, ax=ax, with_curvature=False, alpha=1, vmin=0,\n",
    "                         # vmin=np.min(correlation),\n",
    "                         vmax=np.max(correlation), colorbar_location=[0.75, 0.05, 0.2, 0.05])\n",
    "plt.show()"
   ],
   "id": "8f59402dbd0c7cd1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
