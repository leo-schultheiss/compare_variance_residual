{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T12:44:19.070265Z",
     "start_time": "2025-02-22T12:44:18.714633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import simplstyles\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import voxelwise_tutorials.viz as viz\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from voxelwise_tutorials.io import load_hdf5_array"
   ],
   "id": "b5dc9c4e71fd8255",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T12:44:19.076098Z",
     "start_time": "2025-02-22T12:44:19.073409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_path(language_model, feature, modality, subject, low_level_feature, layer):\n",
    "    path = os.path.join(\"results\", language_model, feature, modality, f\"subject{subject:02}\", low_level_feature,\n",
    "                        f\"layer{layer}\")\n",
    "    return path"
   ],
   "id": "e974193db6e9033a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T12:44:19.161097Z",
     "start_time": "2025-02-22T12:44:19.159141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.style.use('nord-light-talk')\n",
    "data_dir = \"../data\""
   ],
   "id": "4865fc9191590ff5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T12:44:19.205964Z",
     "start_time": "2025-02-22T12:44:19.203444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "language_model = \"bert-base\"\n",
    "feature = \"semantic\"\n",
    "modality = \"reading\"\n",
    "subject = 1\n",
    "layer = 9\n",
    "low_level_feature = \"letters\"\n",
    "trim = 5  # remove 5 TRs from the start and end of each story"
   ],
   "id": "75f6b6cc5a72a947",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Features",
   "id": "9a8914d9d0cdb926"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Low Level Feature",
   "id": "d0cd231fefc1774f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T12:44:19.257794Z",
     "start_time": "2025-02-22T12:44:19.252667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "low_level_train = h5py.File(os.path.join(data_dir, 'features', 'features_trn_NEW.hdf'), 'r')\n",
    "low_level_val = h5py.File(os.path.join(data_dir, 'features', 'features_val_NEW.hdf'), 'r')\n",
    "print(low_level_train.keys())\n",
    "print(low_level_val.keys())"
   ],
   "id": "e761e64fd154e7e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['story_01', 'story_02', 'story_03', 'story_04', 'story_05', 'story_06', 'story_07', 'story_08', 'story_09', 'story_10']>\n",
      "<KeysViewHDF5 ['story_11']>\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T12:44:19.327293Z",
     "start_time": "2025-02-22T12:44:19.303674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "low_level_train = np.vstack(\n",
    "    [zscore(low_level_train[story][low_level_feature][trim:-trim]) for story in low_level_train.keys()])\n",
    "low_level_val = np.vstack(\n",
    "    [zscore(low_level_val[story][low_level_feature][trim:-trim]) for story in low_level_val.keys()])\n",
    "low_level_train, low_level_val = np.nan_to_num(low_level_train), np.nan_to_num(low_level_val)\n",
    "low_level_train"
   ],
   "id": "dbc1a7e7f96a875a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4700195 , -0.73438869,  0.4915585 , ..., -0.1790036 ,\n",
       "         0.34119878, -0.11434134],\n",
       "       [ 0.25931483,  1.02067184, -0.91108246, ..., -0.1790036 ,\n",
       "        -0.2714388 , -0.11434134],\n",
       "       [-1.62907001, -0.35271967, -0.80764183, ..., -0.1790036 ,\n",
       "         0.33492298, -0.11434134],\n",
       "       ...,\n",
       "       [ 0.18454009, -0.5399342 , -0.66761462, ..., -0.28713784,\n",
       "        -0.48108308, -0.13844843],\n",
       "       [-1.25051674, -0.5676835 , -0.69646574, ..., -0.28713784,\n",
       "         0.23124328, -0.13844843],\n",
       "       [-1.28809956, -0.5676835 , -0.69672374, ..., -0.28713784,\n",
       "        -1.19791374, -0.13844843]], shape=(3787, 26))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load High Level (NLP) Features",
   "id": "5ba918368c5f7de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T12:44:19.358165Z",
     "start_time": "2025-02-22T12:44:19.356202Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3d85bea9cacd735b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Brain Data",
   "id": "21566d9ac985f3c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T12:44:29.816800Z",
     "start_time": "2025-02-22T12:44:19.398812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Y_train_filename = os.path.join(data_dir, 'responses', f'subject{subject:02}_{modality}_fmri_data_trn.hdf')\n",
    "Y_train = load_hdf5_array(Y_train_filename)\n",
    "\n",
    "Y_test_filename = os.path.join(data_dir, 'responses', f'subject{subject:02}_{modality}_fmri_data_val.hdf')\n",
    "Y_test = load_hdf5_array(Y_test_filename)\n",
    "\n",
    "Y_train = np.vstack([zscore(Y_train[story][trim:-trim]) for story in Y_train.keys()])\n",
    "Ys_test = [np.vstack([zscore(Y_test[story][i][trim:-trim]) for story in Y_test.keys()]) for i in range(2)]"
   ],
   "id": "c03613f2231ff7e4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19542/591648698.py:7: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][trim:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_19542/591648698.py:7: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][trim:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_19542/591648698.py:7: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][trim:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_19542/591648698.py:7: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][trim:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_19542/591648698.py:7: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][trim:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_19542/591648698.py:7: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][trim:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_19542/591648698.py:7: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][trim:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_19542/591648698.py:7: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][trim:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_19542/591648698.py:7: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][trim:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_19542/591648698.py:7: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Y_train = np.vstack([zscore(Y_train[story][trim:-trim]) for story in Y_train.keys()])\n",
      "/tmp/ipykernel_19542/591648698.py:8: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Ys_test = [np.vstack([zscore(Y_test[story][i][trim:-trim]) for story in Y_test.keys()]) for i in range(2)]\n",
      "/tmp/ipykernel_19542/591648698.py:8: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  Ys_test = [np.vstack([zscore(Y_test[story][i][trim:-trim]) for story in Y_test.keys()]) for i in range(2)]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Variance Partitioning",
   "id": "3451b505f2a885bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Low Level Prediction",
   "id": "e2d6bc50614f533f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "Rstim, Pstim = load_z_low_level_feature(data_dir, low_level_feature)\n",
    "\n",
    "# delay stimuli to account for hemodynamic lag\n",
    "delays = range(1, number_of_delays + 1)\n",
    "ct = ColumnTransformer([(\"low_level\", Delayer(delays), slice(0, Rstim.shape[1] - 1))])\n",
    "\n",
    "# fit bootstrapped ridge regression model\n",
    "corrs, coef, alphas = bootstrap_ridge(Rstim, Rresp, Pstim, Presp, ct)\n",
    "\n",
    "# save voxelwise correlations and predictions\n",
    "output_file = get_prediction_path(language_model=None, feature=\"low-level\", modality=modality, subject=subject_num,\n",
    "                                  low_level_feature=low_level_feature)\n",
    "output_dir = os.path.dirname(output_file)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "np.save(output_file, corrs)"
   ],
   "id": "84b8f06dc5b7c2d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Residual Method",
   "id": "4c7615c170ab5a2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T12:44:29.866863Z",
     "start_time": "2025-02-22T12:44:29.865447Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2c51f150e6695d95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plot Brain Maps",
   "id": "954bdd603b46c57d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T12:44:29.914547Z",
     "start_time": "2025-02-22T12:44:29.908764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_flatmap_from_mapper(voxels, mapper_file, ax=None, alpha=0.7, cmap=plt.get_cmap(), vmin=None, vmax=None,\n",
    "                             with_curvature=True, with_rois=True, with_colorbar=True,\n",
    "                             colorbar_location=(.4, .9, .2, .05)):\n",
    "    \"\"\"Plot a flatmap from a mapper file, with 1D data.\n",
    "\n",
    "    This function is equivalent to the pycortex functions:\n",
    "    cortex.quickshow(cortex.Volume(voxels, ...), ...)\n",
    "\n",
    "    Note that this function does not have the full capability of pycortex,\n",
    "    since it is based on flatmap mappers and not on the original brain\n",
    "    surface of the subject.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    voxels : array of shape (n_voxels, )\n",
    "        Data to be plotted.\n",
    "    mapper_file : str\n",
    "        File name of the mapper.\n",
    "    ax : matplotlib Axes or None.\n",
    "        Axes where the figure will be plotted.\n",
    "        If None, a new figure is created.\n",
    "    alpha : float in [0, 1], or array of shape (n_voxels, )\n",
    "        Transparency of the flatmap.\n",
    "    cmap : str\n",
    "        Name of the matplotlib colormap.\n",
    "    vmin : float or None\n",
    "        Minimum value of the colormap. If None, use the 1st percentile of the\n",
    "        `voxels` array.\n",
    "    vmax : float or None\n",
    "        Minimum value of the colormap. If None, use the 99th percentile of the\n",
    "        `voxels` array.\n",
    "    with_curvature : bool\n",
    "        If True, show the curvature below the data layer.\n",
    "    with_rois : bool\n",
    "        If True, show the ROIs labels above the data layer.\n",
    "    colorbar_location : [left, bottom, width, height]\n",
    "        Location of the colorbar. All quantities are in fractions of figure\n",
    "        width and height.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ax : matplotlib Axes\n",
    "        Axes where the figure has been plotted.\n",
    "    \"\"\"\n",
    "    # create a figure\n",
    "    if ax is None:\n",
    "        flatmap_mask = load_hdf5_array(mapper_file, key='flatmap_mask')\n",
    "        figsize = np.array(flatmap_mask.shape) / 100.\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_axes((0, 0, 1, 1))\n",
    "        ax.axis('off')\n",
    "\n",
    "    # process plotting parameters\n",
    "    vmin = np.percentile(voxels, 1) if vmin is None else vmin\n",
    "    vmax = np.percentile(voxels, 99) if vmax is None else vmax\n",
    "    if isinstance(alpha, np.ndarray):\n",
    "        alpha = viz.map_voxels_to_flatmap(alpha, mapper_file)\n",
    "\n",
    "    # plot the data\n",
    "    image = viz.map_voxels_to_flatmap(voxels, mapper_file)\n",
    "    cimg = ax.imshow(image, aspect='equal', zorder=1, alpha=alpha, cmap=cmap,\n",
    "                     vmin=vmin, vmax=vmax)\n",
    "\n",
    "    if with_colorbar:\n",
    "        try:\n",
    "            cbar = ax.inset_axes(colorbar_location)\n",
    "        except AttributeError:  # for matplotlib < 3.0\n",
    "            cbar = ax.figure.add_axes(colorbar_location)\n",
    "        colorbar = ax.figure.colorbar(cimg, cax=cbar, orientation='horizontal')\n",
    "        colorbar.ax.set_title(\"Pearson Correlation of Y_true and Y_pred\", fontsize=14)\n",
    "\n",
    "    # plot additional layers if present\n",
    "    viz._plot_addition_layers(ax=ax, n_voxels=voxels.shape[0],\n",
    "                              mapper_file=mapper_file,\n",
    "                              with_curvature=with_curvature, with_rois=with_rois)\n",
    "\n",
    "    return ax"
   ],
   "id": "31138f1d9ccc8738",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T12:44:42.241953Z",
     "start_time": "2025-02-22T12:44:42.214281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = get_path(language_model, feature, modality, subject, low_level_feature, layer)\n",
    "correlation = np.nan_to_num(np.load(path, allow_pickle=True))\n",
    "mapper_path = os.path.join(\"../data\",'mappers', f\"subject{subject:02}_mappers.hdf\")\n",
    "flatmap_mask = load_hdf5_array(mapper_path, key='flatmap_mask')"
   ],
   "id": "e415d17fbe50326e",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/bert-base/semantic/reading/subject01/letters/layer9'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m path \u001B[38;5;241m=\u001B[39m get_path(language_model, feature, modality, subject, low_level_feature, layer)\n\u001B[0;32m----> 2\u001B[0m correlation \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mnan_to_num(\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_pickle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m)\n\u001B[1;32m      3\u001B[0m mapper_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmappers\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msubject\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msubject\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m02\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_mappers.hdf\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m flatmap_mask \u001B[38;5;241m=\u001B[39m load_hdf5_array(mapper_path, key\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mflatmap_mask\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:451\u001B[0m, in \u001B[0;36mload\u001B[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[0m\n\u001B[1;32m    449\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 451\u001B[0m     fid \u001B[38;5;241m=\u001B[39m stack\u001B[38;5;241m.\u001B[39menter_context(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    452\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    454\u001B[0m \u001B[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001B[39;00m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'results/bert-base/semantic/reading/subject01/letters/layer9'"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "figsize = np.array(flatmap_mask.shape) / 100.\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_axes((0, 0, 1, 1))\n",
    "ax.axis('off')\n",
    "plot_flatmap_from_mapper(correlation, mapper_path, ax=ax, with_curvature=False, alpha=1, vmin=0,\n",
    "                         # vmin=np.min(correlation),\n",
    "                         vmax=np.max(correlation), colorbar_location=[0.75, 0.05, 0.2, 0.05])\n",
    "plt.show()"
   ],
   "id": "8f59402dbd0c7cd1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
