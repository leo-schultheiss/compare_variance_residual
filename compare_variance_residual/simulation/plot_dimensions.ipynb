{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from himalaya.backend import set_backend\n",
    "from matplotlib import pyplot as plt\n",
    "import simplstyles\n",
    "\n",
    "from residual import residual_method\n",
    "from dataset import generate_dataset\n",
    "from variance_partitioning import variance_partitioning"
   ],
   "id": "4bed5994b7434607"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_path(alphas, cv, n_targets):\n",
    "    path = os.path.join(\"results\", f\"targets={n_targets}\", f\"cv={cv}\",\n",
    "                        f\"alphas={alphas.min()},{alphas.max()},{len(alphas)}\", \"varying dimensions\")\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    return path"
   ],
   "id": "bef0a18e84d89542"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def save_scores(d_list_list, scalars, n_targets, n_samples, noise_target, cv, alphas):\n",
    "    path = get_path(alphas, cv, n_targets)\n",
    "    for d_list in d_list_list:\n",
    "        print(d_list)\n",
    "        csv_path = os.path.join(path, f\"scores_{d_list}.csv\")\n",
    "        scores = pd.DataFrame()\n",
    "        if os.path.exists(csv_path):\n",
    "            print(\"skipping, already exists\")\n",
    "            continue\n",
    "        Xs, Y = generate_dataset(d_list, scalars, n_targets, n_samples, noise_target)\n",
    "        print(\"data generated\")\n",
    "        x1_score, x2_score, joint_score, x1_and_x2_score, vp_x1_unique_score, vp_x2_unique_score = variance_partitioning(\n",
    "            Xs, Y, n_samples_train, alphas, cv)\n",
    "        print(\"variance partitioning done\")\n",
    "\n",
    "        scores[\"x1_score\"] = x1_score\n",
    "        scores[\"x2_score\"] = x2_score\n",
    "        scores[\"vp_joint_score\"] = joint_score\n",
    "        scores[\"vp_shared_score\"] = x1_and_x2_score\n",
    "        scores[\"vp_x1_unique_score\"] = vp_x1_unique_score\n",
    "        scores[\"vp_x2_unique_score\"] = vp_x2_unique_score\n",
    "        del x1_score, x2_score, joint_score, x1_and_x2_score, vp_x1_unique_score, vp_x2_unique_score\n",
    "\n",
    "        x2_to_x1_score, x1_to_x2_score, rm_x1_unique_score, rm_x2_unique_score = residual_method(\n",
    "            Xs, Y, n_samples_train, alphas, cv)\n",
    "        print(\"residual method done\")\n",
    "        scores[\"rm_x2_to_x1_score\"] = np.concatenate(\n",
    "            [x2_to_x1_score, np.full(len(rm_x1_unique_score) - len(x2_to_x1_score), np.nan)])\n",
    "        scores[\"rm_x1_to_x2_score\"] = np.concatenate(\n",
    "            [x1_to_x2_score, np.full(len(rm_x1_unique_score) - len(x1_to_x2_score), np.nan)])\n",
    "        scores[\"rm_x1_unique_score\"] = rm_x1_unique_score\n",
    "        scores[\"rm_x2_unique_score\"] = rm_x2_unique_score\n",
    "        del x2_to_x1_score, x1_to_x2_score, rm_x1_unique_score, rm_x2_unique_score\n",
    "\n",
    "        # ridge residual\n",
    "        x2_to_x1_ridge_score, x1_to_x2_ridge_score, rm_ridge_x1_unique_score, rm_ridge_x2_unique_score = residual_method(\n",
    "            Xs, Y, n_samples_train, alphas, cv, use_ols=False)\n",
    "        print(\"residual method done\")\n",
    "        scores[\"rm_ridge_x2_to_x1_score\"] = np.concatenate(\n",
    "            [x2_to_x1_ridge_score, np.full(len(rm_ridge_x1_unique_score) - len(x2_to_x1_ridge_score), np.nan)])\n",
    "        scores[\"rm_ridge_x1_to_x2_score\"] = np.concatenate(\n",
    "            [x1_to_x2_ridge_score, np.full(len(rm_ridge_x1_unique_score) - len(x1_to_x2_ridge_score), np.nan)])\n",
    "        scores[\"rm_ridge_x1_unique_score\"] = rm_ridge_x1_unique_score\n",
    "        scores[\"rm_ridge_x2_unique_score\"] = rm_ridge_x2_unique_score\n",
    "        del x2_to_x1_ridge_score, x1_to_x2_ridge_score, rm_ridge_x1_unique_score, rm_ridge_x2_unique_score\n",
    "\n",
    "        del Xs, Y\n",
    "        scores.to_csv(csv_path, index=False)"
   ],
   "id": "6d3e2c9ec8a32d02"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save scores for varying Dimensions",
   "id": "526a328bd0075b9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "backend = set_backend(\"torch_cuda\", on_error=\"warn\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(42)\n",
    "plt.style.use('nord-light-talk')"
   ],
   "id": "fcba841de6abb55a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "d_list = [100, 100, 100]\n",
    "n_targets = 10000\n",
    "n_samples_train = 10000\n",
    "n_samples_test = 10000\n",
    "n_samples = n_samples_train + n_samples_test\n",
    "noise_target = 0.1\n",
    "scalars = [1 / 3, 1 / 3, 1 / 3]\n",
    "\n",
    "cv = 10\n",
    "alphas = np.logspace(-5, 5, 10)"
   ],
   "id": "2202753b02de636f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "varying_dim = np.logspace(1, 3, 20, dtype=int)\n",
    "varying_dim = list(map(int, varying_dim))"
   ],
   "id": "2e161f27aed0b36f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Shared dimension",
   "id": "6bd6124efb190b05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "d_list_list = [[dim, d_list[1], d_list[2]] for dim in varying_dim]",
   "id": "f8b1ebd6b349da6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "save_scores(d_list_list, scalars, n_targets, n_samples, noise_target, cv, alphas)",
   "id": "35b5ace844d8183c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Unique dimension",
   "id": "61f9184e6620a8f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "d_list_list = [[d_list[0], int(dim), d_list[2]] for dim in varying_dim]",
   "id": "bf0dbe4a2e087840"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "save_scores(d_list_list, scalars, n_targets, n_samples, noise_target, cv, alphas)",
   "id": "7dcfa567df3cae45"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plot scores",
   "id": "a7ebd9ab83253b58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Shared dimension",
   "id": "400ad83f0fb0b096"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "vp_shared = pd.DataFrame()\n",
    "rm_shared = pd.DataFrame()\n",
    "rm_shared_ridge = pd.DataFrame()\n",
    "\n",
    "for i, dim in enumerate(varying_dim):\n",
    "    shared_dims = [dim, d_list[1], d_list[2]]\n",
    "    scores = pd.read_csv(os.path.join(get_path(alphas, cv, n_targets), f\"scores_{shared_dims}.csv\"))\n",
    "\n",
    "    vp_shared_scores = pd.DataFrame({\n",
    "        'shared_dim': [dim] * len(scores),\n",
    "        'vp_x1_unique_score': scores['vp_x1_unique_score'],\n",
    "    }, index=range(len(scores)))\n",
    "\n",
    "    rm_shared_scores = pd.DataFrame({\n",
    "        'shared_dim': [dim] * len(scores),\n",
    "        'rm_x1_unique_score': scores['rm_x1_unique_score'],\n",
    "    }, index=range(len(scores)))\n",
    "\n",
    "    rm_shared_ridge_scores = pd.DataFrame({\n",
    "        'shared_dim': [dim] * len(scores),\n",
    "        'rm_ridge_x1_unique_score': scores['rm_ridge_x1_unique_score'],\n",
    "    })\n",
    "\n",
    "    vp_shared = pd.concat([vp_shared, vp_shared_scores], ignore_index=True)\n",
    "    rm_shared = pd.concat([rm_shared, rm_shared_scores], ignore_index=True)\n",
    "    rm_shared_ridge = pd.concat([rm_shared_ridge, rm_shared_ridge_scores], ignore_index=True)\n",
    "rm_shared"
   ],
   "id": "29838487d6974cb4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sns.lineplot(data=rm_shared_ridge, x='shared_dim', y='rm_ridge_x1_unique_score', label='Residual Method (Ridge)',\n",
    "             errorbar='sd')\n",
    "sns.lineplot(data=rm_shared, x='shared_dim', y='rm_x1_unique_score', label='Residual Method (OLS)', errorbar='sd')\n",
    "sns.lineplot(data=vp_shared, x='shared_dim', y='vp_x1_unique_score', label='Variance Partitioning', errorbar='sd')\n",
    "plt.axhline(scalars[1] * (1 - noise_target), linestyle='--', label='Expected Value', color=\"C3\")\n",
    "plt.xlabel(r\"$d_\\mathbf{A}$\")\n",
    "plt.ylabel(r\"$R^2$ (mean and sd)\")\n",
    "plt.xscale('log')\n",
    "plt.legend()"
   ],
   "id": "a2b2ccafe93e09cf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Unique dimension",
   "id": "bf0a71d692c8a6af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "vp_unique = pd.DataFrame()\n",
    "rm_unique = pd.DataFrame()\n",
    "rm_unique_ridge = pd.DataFrame()\n",
    "\n",
    "for i, dim in enumerate(varying_dim):\n",
    "    unique_dims = [d_list[0], dim, d_list[2]]\n",
    "    scores = pd.read_csv(os.path.join(get_path(alphas, cv, n_targets), f\"scores_{unique_dims}.csv\"))\n",
    "\n",
    "    vp_unique_scores = pd.DataFrame({\n",
    "        'unique_dim': [dim] * len(scores),\n",
    "        'vp_x1_unique_score': scores['vp_x1_unique_score'],\n",
    "    }, index=range(len(scores)))\n",
    "\n",
    "    rm_unique_scores = pd.DataFrame({\n",
    "        'unique_dim': [dim] * len(scores),\n",
    "        'rm_x1_unique_score': scores['rm_x1_unique_score'],\n",
    "    }, index=range(len(scores)))\n",
    "\n",
    "    rm_unique_ridge_scores = pd.DataFrame({\n",
    "        'unique_dim': [dim] * len(scores),\n",
    "        'rm_ridge_x1_unique_score': scores['rm_ridge_x1_unique_score'],\n",
    "    }, index=range(len(scores)))\n",
    "\n",
    "    vp_unique = pd.concat([vp_unique, vp_unique_scores], ignore_index=True)\n",
    "    rm_unique = pd.concat([rm_unique, rm_unique_scores], ignore_index=True)\n",
    "    rm_unique_ridge = pd.concat([rm_unique_ridge, rm_unique_ridge_scores], ignore_index=True)"
   ],
   "id": "66258bf6cf60f9eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sns.lineplot(data=rm_unique_ridge, x='unique_dim', y='rm_ridge_x1_unique_score', label='Residual Method (Ridge)',\n",
    "             errorbar='sd')\n",
    "sns.lineplot(data=rm_unique, x='unique_dim', y='rm_x1_unique_score', label='Residual Method (OLS)', errorbar='sd')\n",
    "sns.lineplot(data=vp_unique, x='unique_dim', y='vp_x1_unique_score', label='Variance Partitioning', errorbar='sd')\n",
    "plt.axhline(scalars[1] * (1 - noise_target), linestyle='--', label='Expected Value', color=\"C3\")\n",
    "plt.xlabel(r\"$d_\\mathbf{B}$\")\n",
    "plt.ylabel(r\"$R^2$ (mean and sd)\")\n",
    "plt.xscale('log')\n",
    "plt.legend()"
   ],
   "id": "4c89b4b47be68e39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# add label for dotted lines\n",
    "plt.plot([], [], linestyle='-', label=r'$d_\\mathbf{A}$', color='black')\n",
    "plt.plot([], [], linestyle=':', label=r'$d_\\mathbf{B}$', color='black')\n",
    "\n",
    "sns.lineplot(data=rm_shared_ridge, x='shared_dim', y='rm_ridge_x1_unique_score', label='Residual Method (Ridge)',\n",
    "             errorbar='sd', color=\"C0\")\n",
    "sns.lineplot(data=rm_unique_ridge, x='unique_dim', y='rm_ridge_x1_unique_score', errorbar='sd', color=\"C0\",\n",
    "             linestyle=':')\n",
    "sns.lineplot(data=rm_shared, x='shared_dim', y='rm_x1_unique_score', label='Residual Method (OLS)', errorbar='sd',\n",
    "             color=\"C1\")\n",
    "sns.lineplot(data=rm_unique, x='unique_dim', y='rm_x1_unique_score', errorbar='sd', color=\"C1\", linestyle=':')\n",
    "sns.lineplot(data=vp_shared, x='shared_dim', y='vp_x1_unique_score', label='Variance Partitioning', errorbar='sd',\n",
    "             color=\"C2\", )\n",
    "sns.lineplot(data=vp_unique, x='unique_dim', y='vp_x1_unique_score', errorbar='sd', color=\"C2\", linestyle=':')\n",
    "\n",
    "\n",
    "plt.axhline(scalars[1] * (1 - noise_target), linestyle='--', label='Expected Value', color=\"C3\")\n",
    "plt.xlabel(r\"$d_\\mathbf{A/B}$\")\n",
    "plt.ylabel(r\"$R^2$ (mean and sd)\")\n",
    "plt.xscale('log')\n",
    "plt.legend()"
   ],
   "id": "c00d2a83a9a46607"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
