{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:17:32.820146Z",
     "start_time": "2025-02-05T19:17:32.617719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "from importlib import reload\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from himalaya.backend import set_backend\n",
    "from matplotlib import axes\n",
    "\n",
    "from compare_variance_residual.simulation import generate_dataset\n",
    "\n",
    "set_backend(\"cupy\", on_error=\"warn\")\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "529c318b8f13ea16",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:17:32.828547Z",
     "start_time": "2025-02-05T19:17:32.823201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "plt.style.use(\"nord\")\n",
    "sns.set_theme()"
   ],
   "id": "72339f2f171593e1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:17:32.980640Z",
     "start_time": "2025-02-05T19:17:32.976316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generic_errorbar_plot(means, variances, labels, horizontal_positions, title, suptitle, ylabel, xlabel,\n",
    "                          n_samples_train, n_samples_test, ax: axes.Axes = None, fig=None):\n",
    "    \"\"\"Generic plot function for shared parameters between vp_errorbar and rm_errorbar.\"\"\"\n",
    "\n",
    "    if ax is None or fig is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    yerr = [np.sqrt(var) / np.sqrt(n_samples_test) for var in variances]\n",
    "    colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\", \"tab:brown\"]\n",
    "\n",
    "    # Create bar plot\n",
    "    bars = ax.bar(range(len(means)), means, color=colors[:len(means)], yerr=yerr, capsize=5, ecolor=\"black\")\n",
    "    ax.bar_label(bars, fmt='{:,.2f}', label_type='center')\n",
    "    ax.set_xticks(range(len(means)), labels=labels)\n",
    "\n",
    "    # Function to plot horizontal lines\n",
    "    def plot_horizontal_line(start, end, y_value, label, color):\n",
    "        ax.plot([start, end], [y_value, y_value], linestyle='--', label=label, color=color)\n",
    "\n",
    "    # Plot horizontal lines\n",
    "    for i, (y_value, label, start, end) in enumerate(horizontal_positions):\n",
    "        plot_horizontal_line(start, end, y_value, label, colors[i % len(colors)])\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    ylims = ax.get_ylim()\n",
    "    ax.set_ylim(ylims[0], 1.01)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(xlabel)\n",
    "\n",
    "    fig.suptitle(suptitle)\n",
    "    ax.set_title(title)\n",
    "    return ax, fig"
   ],
   "id": "72bd87122cb8b060",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:17:33.022642Z",
     "start_time": "2025-02-05T19:17:33.019982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_space_dimensions = [\n",
    "    100,  # shared\n",
    "    100,  # unique 0\n",
    "    100,  # unique 1\n",
    "]\n",
    "scalars = [\n",
    "    1 / 3, 1 / 3, 1 / 3\n",
    "]\n",
    "n_targets = 1000\n",
    "n_samples_train = 10000\n",
    "n_samples_test = 1000\n",
    "n_samples = n_samples_train + n_samples_test\n",
    "noise_scalar = 0.1\n",
    "\n",
    "cv = 20\n",
    "alphas = np.logspace(-4, 4, 10)"
   ],
   "id": "cd6bbd72f85463dc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:17:35.030562Z",
     "start_time": "2025-02-05T19:17:33.066079Z"
    }
   },
   "cell_type": "code",
   "source": "Xs, Y = generate_dataset(feature_space_dimensions, scalars, n_targets, n_samples, noise_scalar)",
   "id": "3599f619506dac2a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:17:36.844747Z",
     "start_time": "2025-02-05T19:17:35.037235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scalars_alt = [0.6, 0.3, 0.1]\n",
    "scalars_alt = scalars\n",
    "Xs_alt, Y_alt = generate_dataset(feature_space_dimensions, scalars_alt, n_targets, n_samples, noise_scalar,\n",
    "                                 shuffle=False)"
   ],
   "id": "169194a4a52e5fe7",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Variance Partitioning",
   "id": "38925c28bd0a0a32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:17:36.856833Z",
     "start_time": "2025-02-05T19:17:36.852566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def vp_errorbar(score_0, score_1, joint_score, shared, x0_unique, x1_unique, feature_space_dimensions, scalars,\n",
    "                n_targets, n_samples_train, n_samples_test, noise_scalar, ax: axes.Axes = None, fig=None):\n",
    "    # Precompute means and variances\n",
    "    scores = [score_0, score_1, joint_score, shared, x0_unique, x1_unique]\n",
    "    means = [s.mean() for s in scores]\n",
    "    variances = [s.var() for s in scores]\n",
    "\n",
    "    bar_names = [r\"$X_0$\", r\"$X_1$\", r\"$X_0 \\cup X_1$\", r\"$X_0 \\cap X_1$\", r\"$X_0 \\setminus X_1$\",\n",
    "                 r\"$X_1 \\setminus X_0$\"]\n",
    "\n",
    "    # Horizontal line positions\n",
    "    horizontal_positions = [\n",
    "        (scalars[0] + scalars[1], r\"$a_S + a_{U_0}$\", -0.5, 0.5),\n",
    "        (scalars[0] + scalars[2], r\"$a_S + a_{U_1}$\", 0.5, 1.5),\n",
    "        (sum(scalars), r\"$a_S + a_{U_0} + a_{U_1}$\", 1.5, 2.5),\n",
    "        (scalars[0], r\"$a_S$\", 2.5, 3.5),\n",
    "        (scalars[1], r\"$a_{U_0}$\", 3.5, 4.5),\n",
    "        (scalars[2], r\"$a_{U_1}$\", 4.5, 5.5)\n",
    "    ]\n",
    "\n",
    "    # Call the generic function\n",
    "    generic_errorbar_plot(\n",
    "        means=means,\n",
    "        variances=variances,\n",
    "        labels=bar_names,\n",
    "        horizontal_positions=horizontal_positions,\n",
    "        title=fr\"$a_S$: {scalars[0]:.2f}, $a_{{U_0}}$: {scalars[1]:.2f}, $a_{{U_1}}$: {scalars[2]:.2f}, $|S|$: {feature_space_dimensions[0]}, $|U_0|$: {feature_space_dimensions[1]}, $|U_1|$: {feature_space_dimensions[2]}, $a_E$: {noise_scalar}\",\n",
    "        suptitle=\"Variance partitioning\",\n",
    "        ylabel=r\"Average Variance Explained ($r^2$)\",\n",
    "        xlabel=\"Feature space\",\n",
    "        n_samples_test=n_samples_test,\n",
    "        n_samples_train=n_samples_train,\n",
    "        ax=ax,\n",
    "        fig=fig\n",
    "    )"
   ],
   "id": "46bc2793fe4447fd",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:17:36.901789Z",
     "start_time": "2025-02-05T19:17:36.900055Z"
    }
   },
   "cell_type": "code",
   "source": "from compare_variance_residual.variance_partitioning import variance_partitioning",
   "id": "e90d33f76031cd16",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:18:17.113606Z",
     "start_time": "2025-02-05T19:17:36.946260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(score_0, score_1, joint_score, shared, x0_unique, x1_unique) = variance_partitioning(\n",
    "    Xs, Y, n_samples_train, cv=cv, alphas=alphas, logger=logger\n",
    ")"
   ],
   "id": "b76380e34d732325",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:18:17.819547Z",
     "start_time": "2025-02-05T19:18:17.135784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(score_0_alt, score_1_alt, joint_score_alt, shared_alt, x0_unique_alt, x1_unique_alt) = variance_partitioning(\n",
    "    Xs_alt, Y_alt, n_samples_train, alphas, cv, logger\n",
    ")"
   ],
   "id": "9d4aec740f5c6237",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'RootLogger' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m (score_0_alt, score_1_alt, joint_score_alt, shared_alt, x0_unique_alt, x1_unique_alt) \u001B[38;5;241m=\u001B[39m \u001B[43mvariance_partitioning\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mXs_alt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_alt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_samples_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malphas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogger\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/compare_variance_residual/variance_partitioning.py:63\u001B[0m, in \u001B[0;36mvariance_partitioning\u001B[0;34m(Xs, Y, n_samples_train, alphas, cv, score_func, use_ols, logger)\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;66;03m# train joint model\u001B[39;00m\n\u001B[1;32m     61\u001B[0m joint_model \u001B[38;5;241m=\u001B[39m GroupRidgeCV(groups\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput\u001B[39m\u001B[38;5;124m\"\u001B[39m, solver_params\u001B[38;5;241m=\u001B[39msolver_params)\n\u001B[0;32m---> 63\u001B[0m \u001B[43mjoint_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43mn_samples_train\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mXs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43mn_samples_train\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     64\u001B[0m joint_score \u001B[38;5;241m=\u001B[39m joint_model\u001B[38;5;241m.\u001B[39mscore([x[n_samples_train:] \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m Xs], Y[n_samples_train:])\n\u001B[1;32m     66\u001B[0m \u001B[38;5;66;03m# train single models\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/himalaya/backend/_utils.py:97\u001B[0m, in \u001B[0;36mforce_cpu_backend.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     95\u001B[0m     \u001B[38;5;66;03m# skip if the object does not force cpu use\u001B[39;00m\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(args[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mforce_cpu\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mforce_cpu:\n\u001B[0;32m---> 97\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;66;03m# set corresponding cpu backend\u001B[39;00m\n\u001B[1;32m    100\u001B[0m     original_backend \u001B[38;5;241m=\u001B[39m get_backend()\u001B[38;5;241m.\u001B[39mname\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/himalaya/ridge/_sklearn_api.py:501\u001B[0m, in \u001B[0;36mGroupRidgeCV.fit\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m    498\u001B[0m cv \u001B[38;5;241m=\u001B[39m check_cv(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv, y)\n\u001B[1;32m    500\u001B[0m \u001B[38;5;66;03m# ------------------ call the solver\u001B[39;00m\n\u001B[0;32m--> 501\u001B[0m tmp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_solver\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mXs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    503\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mfit_intercept\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_intercept\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    504\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mY_in_cpu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mY_in_cpu\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    505\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_intercept:\n\u001B[1;32m    506\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdeltas_, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoef_, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv_scores_ \u001B[38;5;241m=\u001B[39m tmp[:\u001B[38;5;241m3\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/himalaya/ridge/_sklearn_api.py:44\u001B[0m, in \u001B[0;36m_BaseRidge._call_solver\u001B[0;34m(self, **direct_params)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m intersection:\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     40\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mParameters \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m should not be given in solver_params, since \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     41\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthey are either fixed or have a direct parameter in \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m     42\u001B[0m         (intersection, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m))\n\u001B[0;32m---> 44\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdirect_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msolver_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/himalaya/ridge/_random_search.py:242\u001B[0m, in \u001B[0;36msolve_group_ridge_random_search\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m warnings\u001B[38;5;241m.\u001B[39mcatch_warnings():\n\u001B[1;32m    240\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m, category\u001B[38;5;241m=\u001B[39m\u001B[38;5;167;01mUserWarning\u001B[39;00m)\n\u001B[1;32m    241\u001B[0m     scores[jj, alpha_batch,\n\u001B[0;32m--> 242\u001B[0m            batch] \u001B[38;5;241m=\u001B[39m \u001B[43mscore_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mYtest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    243\u001B[0m     \u001B[38;5;66;03m# n_alphas_batch, n_targets_batch = score.shape\u001B[39;00m\n\u001B[1;32m    244\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m Ytrain, Ytest\n",
      "\u001B[0;31mTypeError\u001B[0m: 'RootLogger' object is not callable"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "vp_errorbar(score_0, score_1, joint_score, shared, x0_unique, x1_unique, feature_space_dimensions, scalars, n_targets,\n",
    "            n_samples_train, n_samples_test, noise_scalar, ax=axs[0], fig=fig)\n",
    "axs[0].set_title(\"Shuffled\")\n",
    "\n",
    "vp_errorbar(score_0_alt, score_1_alt, joint_score_alt, shared_alt, x0_unique_alt, x1_unique_alt,\n",
    "            feature_space_dimensions, scalars_alt, n_targets,\n",
    "            n_samples_train, n_samples_test, noise_scalar, ax=axs[1], fig=fig)\n",
    "axs[1].set_title(\"Descending\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "b1276f61678c56c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Residual Method",
   "id": "3bbabd3112271167"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from compare_variance_residual.residual import residual_method",
   "id": "1900783e21f6d5af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def rm_errorbar(full_score_0, full_score_1, feature_score_0, feature_score_1, residual_score_0, residual_scores_1,\n",
    "                feature_space_dimensions, scalars,\n",
    "                n_targets, n_samples_train, n_samples_test, noise_scalar, ax: axes.Axes = None, fig=None):\n",
    "    if ax is None or fig is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    # Precompute means and variances\n",
    "    scores = [full_score_0, full_score_1, feature_score_0, feature_score_1, residual_score_0, residual_scores_1]\n",
    "    means = [s.mean() for s in scores]\n",
    "    variances = [s.var() for s in scores]\n",
    "\n",
    "    bar_names = [r\"$X_0$\", r\"$X_1$\", r\"$X_1 \\rightarrow X_0$\", r\"$X_0 \\rightarrow X_1$\", r\"$X_0 \\setminus X_1$\",\n",
    "                 r\"$X_1 \\setminus X_0$\"]\n",
    "\n",
    "    horizontal_positions = [\n",
    "        (scalars[0] + scalars[1], r\"$a_S + a_{U_0}$\", -0.5, 0.5),\n",
    "        (scalars[0] + scalars[2], r\"$a_S + a_{U_1}$\", 0.5, 1.5),\n",
    "        (feature_space_dimensions[0] / (feature_space_dimensions[0] + feature_space_dimensions[1]),\n",
    "         r\"$\\frac{|S|}{|U_0|+|S|}$\", 1.5, 2.5),\n",
    "        (feature_space_dimensions[0] / (feature_space_dimensions[0] + feature_space_dimensions[2]),\n",
    "         r\"$\\frac{|S|}{|U_1|+|S|}$\", 2.5, 3.5),\n",
    "        (scalars[1], r\"$a_{U_0}$\", 3.5, 4.5),\n",
    "        (scalars[2], r\"$a_{U_1}$\", 4.5, 5.5)\n",
    "    ]\n",
    "\n",
    "    # Call the generic_errorbar function with the required data and parameters\n",
    "    generic_errorbar_plot(\n",
    "        means=means,\n",
    "        variances=variances,\n",
    "        labels=bar_names,\n",
    "        horizontal_positions=horizontal_positions,\n",
    "        title=fr\"{n_targets} targets, $a_S$: {scalars[0]:.2f}, $|S|$: {feature_space_dimensions[0]}, $a_{{U_0}}$: {scalars[1]:.2f}, $|U_0|$: {feature_space_dimensions[1]}, $a_{{U_1}}$: {scalars[2]:.2f}, $|U_1|$: {feature_space_dimensions[2]}, $a_E$: {noise_scalar}\",\n",
    "        suptitle=\"Residual Method\",\n",
    "        ylabel=r\"Average Variance Explained ($r^2$)\",\n",
    "        xlabel=\"Feature space/Model\",\n",
    "        n_samples_test=n_samples_test,\n",
    "        n_samples_train=n_samples_train,\n",
    "        ax=ax,\n",
    "        fig=fig\n",
    "    )"
   ],
   "id": "1c4e4f477d4c7b8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "full_score_0, full_score_1, feature_score_0, feature_score_1, residual_score_0, residual_scores_1 = residual_method(\n",
    "    Xs, Y, n_samples_train, cv=cv\n",
    ")\n",
    "full_score_0_alt, full_score_1_alt, feature_score_0_alt, feature_score_1_alt, residual_score_0_alt, residual_scores_1_alt = residual_method(\n",
    "    Xs_alt, Y_alt, n_samples_train, cv=cv\n",
    ")"
   ],
   "id": "ec6a571e97d304b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "rm_errorbar(full_score_0, full_score_1, feature_score_0, feature_score_1, residual_score_0, residual_scores_1,\n",
    "            feature_space_dimensions, scalars, n_targets, n_samples_train, n_samples_test, noise_scalar, ax=axs[0],\n",
    "            fig=fig)\n",
    "axs[0].set_title(\"Shuffled\")\n",
    "rm_errorbar(full_score_0_alt, full_score_1_alt, feature_score_0_alt, feature_score_1_alt, residual_score_0_alt,\n",
    "            residual_scores_1_alt, feature_space_dimensions, scalars_alt, n_targets, n_samples_train, n_samples_test,\n",
    "            noise_scalar, ax=axs[1], fig=fig)\n",
    "axs[1].set_title(\"Descending\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "aa6438f4ddd7127a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6f97292f52baa499",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
