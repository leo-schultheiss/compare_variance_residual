{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:24:44.579637Z",
     "start_time": "2025-02-05T19:24:44.577172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from himalaya.backend import set_backend\n",
    "from matplotlib import axes\n",
    "\n",
    "from compare_variance_residual.simulation import generate_dataset"
   ],
   "id": "529c318b8f13ea16",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:24:44.630255Z",
     "start_time": "2025-02-05T19:24:44.627057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "backend = set_backend(\"cupy\", on_error=\"warn\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use(\"nord\")\n",
    "sns.set_theme()"
   ],
   "id": "72339f2f171593e1",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:24:44.677906Z",
     "start_time": "2025-02-05T19:24:44.673245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generic_errorbar_plot(means, variances, labels, horizontal_positions, title, suptitle, ylabel, xlabel,\n",
    "                          n_samples_train, n_samples_test, ax: axes.Axes = None, fig=None):\n",
    "    \"\"\"Generic plot function for shared parameters between vp_errorbar and rm_errorbar.\"\"\"\n",
    "\n",
    "    if ax is None or fig is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    yerr = [np.sqrt(var) / np.sqrt(n_samples_test) for var in variances]\n",
    "    colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\", \"tab:brown\"]\n",
    "\n",
    "    # Create bar plot\n",
    "    bars = ax.bar(range(len(means)), means, color=colors[:len(means)], yerr=yerr, capsize=5, ecolor=\"black\")\n",
    "    ax.bar_label(bars, fmt='{:,.2f}', label_type='center')\n",
    "    ax.set_xticks(range(len(means)), labels=labels)\n",
    "\n",
    "    # Function to plot horizontal lines\n",
    "    def plot_horizontal_line(start, end, y_value, label, color):\n",
    "        ax.plot([start, end], [y_value, y_value], linestyle='--', label=label, color=color)\n",
    "\n",
    "    # Plot horizontal lines\n",
    "    for i, (y_value, label, start, end) in enumerate(horizontal_positions):\n",
    "        plot_horizontal_line(start, end, y_value, label, colors[i % len(colors)])\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    ylims = ax.get_ylim()\n",
    "    ax.set_ylim(ylims[0], 1.01)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(xlabel)\n",
    "\n",
    "    fig.suptitle(suptitle)\n",
    "    ax.set_title(title)\n",
    "    return ax, fig"
   ],
   "id": "72bd87122cb8b060",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:24:44.756195Z",
     "start_time": "2025-02-05T19:24:44.753404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_space_dimensions = [\n",
    "    100,  # shared\n",
    "    100,  # unique 0\n",
    "    100,  # unique 1\n",
    "]\n",
    "scalars = [\n",
    "    1 / 3, 1 / 3, 1 / 3\n",
    "]\n",
    "n_targets = 1000\n",
    "n_samples_train = 10000\n",
    "n_samples_test = 1000\n",
    "n_samples = n_samples_train + n_samples_test\n",
    "noise_scalar = 0.1\n",
    "\n",
    "cv = 20\n",
    "alphas = np.logspace(-4, 4, 10)"
   ],
   "id": "cd6bbd72f85463dc",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:24:46.892233Z",
     "start_time": "2025-02-05T19:24:44.800100Z"
    }
   },
   "cell_type": "code",
   "source": "Xs, Y = generate_dataset(feature_space_dimensions, scalars, n_targets, n_samples, noise_scalar)",
   "id": "3599f619506dac2a",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:24:49.315483Z",
     "start_time": "2025-02-05T19:24:46.908071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scalars_alt = [0.6, 0.3, 0.1]\n",
    "Xs_alt, Y_alt = generate_dataset(feature_space_dimensions, scalars_alt, n_targets, n_samples, noise_scalar)"
   ],
   "id": "169194a4a52e5fe7",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Variance Partitioning",
   "id": "38925c28bd0a0a32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:24:49.345836Z",
     "start_time": "2025-02-05T19:24:49.341896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def vp_errorbar(score_0, score_1, joint_score, shared, x0_unique, x1_unique, feature_space_dimensions, scalars,\n",
    "                n_targets, n_samples_train, n_samples_test, noise_scalar, ax: axes.Axes = None, fig=None):\n",
    "    # Precompute means and variances\n",
    "    scores = [score_0, score_1, joint_score, shared, x0_unique, x1_unique]\n",
    "    means = [s.mean() for s in scores]\n",
    "    variances = [s.var() for s in scores]\n",
    "\n",
    "    bar_names = [r\"$X_0$\", r\"$X_1$\", r\"$X_0 \\cup X_1$\", r\"$X_0 \\cap X_1$\", r\"$X_0 \\setminus X_1$\",\n",
    "                 r\"$X_1 \\setminus X_0$\"]\n",
    "\n",
    "    # Horizontal line positions\n",
    "    horizontal_positions = [\n",
    "        (scalars[0] + scalars[1], r\"$a_S + a_{U_0}$\", -0.5, 0.5),\n",
    "        (scalars[0] + scalars[2], r\"$a_S + a_{U_1}$\", 0.5, 1.5),\n",
    "        (sum(scalars), r\"$a_S + a_{U_0} + a_{U_1}$\", 1.5, 2.5),\n",
    "        (scalars[0], r\"$a_S$\", 2.5, 3.5),\n",
    "        (scalars[1], r\"$a_{U_0}$\", 3.5, 4.5),\n",
    "        (scalars[2], r\"$a_{U_1}$\", 4.5, 5.5)\n",
    "    ]\n",
    "\n",
    "    # Call the generic function\n",
    "    generic_errorbar_plot(\n",
    "        means=means,\n",
    "        variances=variances,\n",
    "        labels=bar_names,\n",
    "        horizontal_positions=horizontal_positions,\n",
    "        title=fr\"$a_S$: {scalars[0]:.2f}, $a_{{U_0}}$: {scalars[1]:.2f}, $a_{{U_1}}$: {scalars[2]:.2f}, $|S|$: {feature_space_dimensions[0]}, $|U_0|$: {feature_space_dimensions[1]}, $|U_1|$: {feature_space_dimensions[2]}, $a_E$: {noise_scalar}\",\n",
    "        suptitle=\"Variance partitioning\",\n",
    "        ylabel=r\"Average Variance Explained ($r^2$)\",\n",
    "        xlabel=\"Feature space\",\n",
    "        n_samples_test=n_samples_test,\n",
    "        n_samples_train=n_samples_train,\n",
    "        ax=ax,\n",
    "        fig=fig\n",
    "    )"
   ],
   "id": "46bc2793fe4447fd",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:24:49.391009Z",
     "start_time": "2025-02-05T19:24:49.389053Z"
    }
   },
   "cell_type": "code",
   "source": "from compare_variance_residual.variance_partitioning import variance_partitioning",
   "id": "e90d33f76031cd16",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-05T19:24:49.437662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(score_0, score_1, joint_score, shared, x0_unique, x1_unique) = variance_partitioning(\n",
    "    Xs, Y, n_samples_train, cv=cv, alphas=alphas\n",
    ")"
   ],
   "id": "b76380e34d732325",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(score_0_alt, score_1_alt, joint_score_alt, shared_alt, x0_unique_alt, x1_unique_alt) = variance_partitioning(\n",
    "    Xs_alt, Y_alt, n_samples_train, alphas, cv\n",
    ")"
   ],
   "id": "9d4aec740f5c6237",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "vp_errorbar(score_0, score_1, joint_score, shared, x0_unique, x1_unique, feature_space_dimensions, scalars, n_targets,\n",
    "            n_samples_train, n_samples_test, noise_scalar, ax=axs[0], fig=fig)\n",
    "axs[0].set_title(\"Shuffled\")\n",
    "\n",
    "vp_errorbar(score_0_alt, score_1_alt, joint_score_alt, shared_alt, x0_unique_alt, x1_unique_alt,\n",
    "            feature_space_dimensions, scalars_alt, n_targets,\n",
    "            n_samples_train, n_samples_test, noise_scalar, ax=axs[1], fig=fig)\n",
    "axs[1].set_title(\"Descending\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "b1276f61678c56c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Residual Method",
   "id": "3bbabd3112271167"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from compare_variance_residual.residual import residual_method",
   "id": "1900783e21f6d5af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def rm_errorbar(full_score_0, full_score_1, feature_score_0, feature_score_1, residual_score_0, residual_scores_1,\n",
    "                feature_space_dimensions, scalars,\n",
    "                n_targets, n_samples_train, n_samples_test, noise_scalar, ax: axes.Axes = None, fig=None):\n",
    "    if ax is None or fig is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    # Precompute means and variances\n",
    "    scores = [full_score_0, full_score_1, feature_score_0, feature_score_1, residual_score_0, residual_scores_1]\n",
    "    means = [s.mean() for s in scores]\n",
    "    variances = [s.var() for s in scores]\n",
    "\n",
    "    bar_names = [r\"$X_0$\", r\"$X_1$\", r\"$X_1 \\rightarrow X_0$\", r\"$X_0 \\rightarrow X_1$\", r\"$X_0 \\setminus X_1$\",\n",
    "                 r\"$X_1 \\setminus X_0$\"]\n",
    "\n",
    "    horizontal_positions = [\n",
    "        (scalars[0] + scalars[1], r\"$a_S + a_{U_0}$\", -0.5, 0.5),\n",
    "        (scalars[0] + scalars[2], r\"$a_S + a_{U_1}$\", 0.5, 1.5),\n",
    "        (feature_space_dimensions[0] / (feature_space_dimensions[0] + feature_space_dimensions[1]),\n",
    "         r\"$\\frac{|S|}{|U_0|+|S|}$\", 1.5, 2.5),\n",
    "        (feature_space_dimensions[0] / (feature_space_dimensions[0] + feature_space_dimensions[2]),\n",
    "         r\"$\\frac{|S|}{|U_1|+|S|}$\", 2.5, 3.5),\n",
    "        (scalars[1], r\"$a_{U_0}$\", 3.5, 4.5),\n",
    "        (scalars[2], r\"$a_{U_1}$\", 4.5, 5.5)\n",
    "    ]\n",
    "\n",
    "    # Call the generic_errorbar function with the required data and parameters\n",
    "    generic_errorbar_plot(\n",
    "        means=means,\n",
    "        variances=variances,\n",
    "        labels=bar_names,\n",
    "        horizontal_positions=horizontal_positions,\n",
    "        title=fr\"{n_targets} targets, $a_S$: {scalars[0]:.2f}, $|S|$: {feature_space_dimensions[0]}, $a_{{U_0}}$: {scalars[1]:.2f}, $|U_0|$: {feature_space_dimensions[1]}, $a_{{U_1}}$: {scalars[2]:.2f}, $|U_1|$: {feature_space_dimensions[2]}, $a_E$: {noise_scalar}\",\n",
    "        suptitle=\"Residual Method\",\n",
    "        ylabel=r\"Average Variance Explained ($r^2$)\",\n",
    "        xlabel=\"Feature space/Model\",\n",
    "        n_samples_test=n_samples_test,\n",
    "        n_samples_train=n_samples_train,\n",
    "        ax=ax,\n",
    "        fig=fig\n",
    "    )"
   ],
   "id": "1c4e4f477d4c7b8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "full_score_0, full_score_1, feature_score_0, feature_score_1, residual_score_0, residual_scores_1 = residual_method(\n",
    "    Xs, Y, n_samples_train, cv=cv\n",
    ")\n",
    "full_score_0_alt, full_score_1_alt, feature_score_0_alt, feature_score_1_alt, residual_score_0_alt, residual_scores_1_alt = residual_method(\n",
    "    Xs_alt, Y_alt, n_samples_train, cv=cv\n",
    ")"
   ],
   "id": "ec6a571e97d304b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "rm_errorbar(full_score_0, full_score_1, feature_score_0, feature_score_1, residual_score_0, residual_scores_1,\n",
    "            feature_space_dimensions, scalars, n_targets, n_samples_train, n_samples_test, noise_scalar, ax=axs[0],\n",
    "            fig=fig)\n",
    "axs[0].set_title(\"Shuffled\")\n",
    "rm_errorbar(full_score_0_alt, full_score_1_alt, feature_score_0_alt, feature_score_1_alt, residual_score_0_alt,\n",
    "            residual_scores_1_alt, feature_space_dimensions, scalars_alt, n_targets, n_samples_train, n_samples_test,\n",
    "            noise_scalar, ax=axs[1], fig=fig)\n",
    "axs[1].set_title(\"Descending\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "aa6438f4ddd7127a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6f97292f52baa499",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
