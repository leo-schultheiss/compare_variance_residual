{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T10:27:20.370938Z",
     "start_time": "2025-02-20T10:27:20.275883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from himalaya.backend import set_backend\n",
    "\n",
    "from compare_variance_residual.residual import residual_method\n",
    "from compare_variance_residual.simulation import generate_dataset\n",
    "from compare_variance_residual.variance_partitioning import variance_partitioning"
   ],
   "id": "a6e4652117c39c44",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T10:27:20.390417Z",
     "start_time": "2025-02-20T10:27:20.387509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_path(alphas, cv, n_targets):\n",
    "    path = os.path.join(\"results\", f\"targets={n_targets}\", f\"cv={cv}\",\n",
    "                        f\"alphas={alphas.min()},{alphas.max()},{len(alphas)}\", \"varying training samples\")\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    return path"
   ],
   "id": "ea1c6e965ce969b4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T10:27:20.493721Z",
     "start_time": "2025-02-20T10:27:20.488933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_scores(samples_train, d_list, scalars, n_targets, n_samples, noise_target, cv, alphas):\n",
    "    path = get_path(alphas, cv, n_targets)\n",
    "    for n_samples_train in samples_train:\n",
    "        print(n_samples_train)\n",
    "        csv_path = os.path.join(path, f\"scores_{n_samples_train}.csv\")\n",
    "        scores = pd.DataFrame()\n",
    "        if os.path.exists(csv_path):\n",
    "            print(\"skipping, already exists\")\n",
    "            continue\n",
    "        Xs, Y = generate_dataset(d_list, scalars, n_targets, n_samples, noise_target)\n",
    "        print(\"data generated\")\n",
    "        x1_score, x2_score, joint_score, x1_and_x2_score, vp_x1_unique_score, vp_x2_unique_score = variance_partitioning(\n",
    "            Xs, Y, n_samples_train, alphas, cv)\n",
    "        print(\"variance partitioning done\")\n",
    "\n",
    "        scores[\"x1_score\"] = x1_score\n",
    "        scores[\"x2_score\"] = x2_score\n",
    "        scores[\"vp_joint_score\"] = joint_score\n",
    "        scores[\"vp_shared_score\"] = x1_and_x2_score\n",
    "        scores[\"vp_x1_unique_score\"] = vp_x1_unique_score\n",
    "        scores[\"vp_x2_unique_score\"] = vp_x2_unique_score\n",
    "        del x1_score, x2_score, joint_score, x1_and_x2_score, vp_x1_unique_score, vp_x2_unique_score\n",
    "\n",
    "        _, _, x2_to_x1_score, x1_to_x2_score, rm_x1_unique_score, rm_x2_unique_score = residual_method(\n",
    "            Xs, Y, n_samples_train, alphas, cv)\n",
    "        print(\"residual method done\")\n",
    "        scores[\"rm_x2_to_x1_score\"] = np.concatenate(\n",
    "            [x2_to_x1_score, np.full(len(rm_x1_unique_score) - len(x2_to_x1_score), np.nan)])\n",
    "        scores[\"rm_x1_to_x2_score\"] = np.concatenate(\n",
    "            [x1_to_x2_score, np.full(len(rm_x1_unique_score) - len(x1_to_x2_score), np.nan)])\n",
    "        scores[\"rm_x1_unique_score\"] = rm_x1_unique_score\n",
    "        scores[\"rm_x2_unique_score\"] = rm_x2_unique_score\n",
    "        print(scores.head())\n",
    "        del x2_to_x1_score, x1_to_x2_score, rm_x1_unique_score, rm_x2_unique_score\n",
    "        del Xs, Y\n",
    "        scores.to_csv(csv_path, index=False)"
   ],
   "id": "4ef8b162998033d8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save scores for varying training samples",
   "id": "73067f9557e453ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T10:27:20.777638Z",
     "start_time": "2025-02-20T10:27:20.536641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "backend = set_backend(\"cupy\", on_error=\"warn\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(42)"
   ],
   "id": "cc72256f30bdfbe5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T10:27:20.786780Z",
     "start_time": "2025-02-20T10:27:20.783365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d_list = [100, 100, 100]\n",
    "n_targets = 10000\n",
    "n_samples_train = 10000\n",
    "n_samples_test = 100\n",
    "n_samples = n_samples_train + n_samples_test\n",
    "scalars = [1 / 3, 1 / 3, 1 / 3]\n",
    "noise_target = 0.1\n",
    "\n",
    "cv = 10\n",
    "alphas = np.logspace(-5, 5, 10)"
   ],
   "id": "b214df113195e135",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T10:27:20.838729Z",
     "start_time": "2025-02-20T10:27:20.836292Z"
    }
   },
   "cell_type": "code",
   "source": "samples_train = np.logspace(1, 6, 6).astype(int)",
   "id": "b9718c25b12815d3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T10:28:55.393570Z",
     "start_time": "2025-02-20T10:27:20.890415Z"
    }
   },
   "cell_type": "code",
   "source": "save_scores(samples_train, d_list, scalars, n_targets, n_samples, noise_target, cv, alphas)",
   "id": "735685771e18af5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "data generated\n",
      "variance partitioning done\n",
      "   x1_score  x2_score  vp_joint_score  vp_shared_score  vp_x1_unique_score  \\\n",
      "0  0.000286  0.000390        0.012749        -0.012073            0.012359   \n",
      "1  0.000221  0.000306        0.001964        -0.001437            0.001658   \n",
      "2  0.000200  0.000244       -0.012319         0.012763           -0.012563   \n",
      "3  0.000232  0.000153       -0.000929         0.001314           -0.001082   \n",
      "4  0.000072  0.000163        0.001722        -0.001487            0.001558   \n",
      "\n",
      "   vp_x2_unique_score  \n",
      "0            0.012462  \n",
      "1            0.001743  \n",
      "2           -0.012519  \n",
      "3           -0.001161  \n",
      "4            0.001650  \n",
      "residual method done\n",
      "177\n",
      "data generated\n",
      "variance partitioning done\n",
      "   x1_score  x2_score  vp_joint_score  vp_shared_score  vp_x1_unique_score  \\\n",
      "0  0.237087  0.226791        0.282811         0.181067            0.056020   \n",
      "1  0.199447  0.200823        0.368740         0.031530            0.167917   \n",
      "2  0.246920  0.231987        0.334350         0.144557            0.102363   \n",
      "3  0.235400  0.204462        0.391808         0.048054            0.187346   \n",
      "4  0.200303  0.207784        0.365504         0.042583            0.157720   \n",
      "\n",
      "   vp_x2_unique_score  \n",
      "0            0.045723  \n",
      "1            0.169293  \n",
      "2            0.087430  \n",
      "3            0.156409  \n",
      "4            0.165201  \n",
      "residual method done\n",
      "3162\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43msave_scores\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscalars\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_targets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnoise_target\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malphas\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[3], line 10\u001B[0m, in \u001B[0;36msave_scores\u001B[0;34m(samples_train, d_list, scalars, n_targets, n_samples, noise_target, cv, alphas)\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskipping, already exists\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m Xs, Y \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43md_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscalars\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_targets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnoise_target\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata generated\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     12\u001B[0m x1_score, x2_score, joint_score, x1_and_x2_score, vp_x1_unique_score, vp_x2_unique_score \u001B[38;5;241m=\u001B[39m variance_partitioning(\n\u001B[1;32m     13\u001B[0m     Xs, Y, n_samples_train, alphas, cv)\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/compare_variance_residual/simulation.py:105\u001B[0m, in \u001B[0;36mgenerate_dataset\u001B[0;34m(d_list, scalars, n_targets, n_samples, noise_target, noise_features, construction_method, random_state)\u001B[0m\n\u001B[1;32m    102\u001B[0m Y \u001B[38;5;241m=\u001B[39m zscore(Y)\n\u001B[1;32m    104\u001B[0m \u001B[38;5;66;03m# add noise\u001B[39;00m\n\u001B[0;32m--> 105\u001B[0m noise \u001B[38;5;241m=\u001B[39m \u001B[43mzscore\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_targets\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    106\u001B[0m Y \u001B[38;5;241m=\u001B[39m ((\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m noise_target) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.5\u001B[39m) \u001B[38;5;241m*\u001B[39m Y \u001B[38;5;241m+\u001B[39m noise \u001B[38;5;241m*\u001B[39m (noise_target \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.5\u001B[39m)\n\u001B[1;32m    107\u001B[0m Y \u001B[38;5;241m=\u001B[39m zscore(Y)\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/scipy/stats/_stats_py.py:2722\u001B[0m, in \u001B[0;36mzscore\u001B[0;34m(a, axis, ddof, nan_policy)\u001B[0m\n\u001B[1;32m   2640\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mzscore\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, ddof\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, nan_policy\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpropagate\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m   2641\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2642\u001B[0m \u001B[38;5;124;03m    Compute the z score.\u001B[39;00m\n\u001B[1;32m   2643\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2720\u001B[0m \u001B[38;5;124;03m           [-0.91611681, -0.89090508,  1.4983032 ,  0.88731639, -0.5785977 ]])\u001B[39;00m\n\u001B[1;32m   2721\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2722\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mzmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mddof\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mddof\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnan_policy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnan_policy\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/scipy/stats/_stats_py.py:2886\u001B[0m, in \u001B[0;36mzmap\u001B[0;34m(scores, compare, axis, ddof, nan_policy)\u001B[0m\n\u001B[1;32m   2882\u001B[0m     std \u001B[38;5;241m=\u001B[39m _xp_var(compare, axis\u001B[38;5;241m=\u001B[39maxis, correction\u001B[38;5;241m=\u001B[39mddof,\n\u001B[1;32m   2883\u001B[0m                   keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, nan_policy\u001B[38;5;241m=\u001B[39mnan_policy)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m0.5\u001B[39m\n\u001B[1;32m   2885\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(invalid\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m'\u001B[39m, divide\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m-> 2886\u001B[0m     z \u001B[38;5;241m=\u001B[39m \u001B[43m_demean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscores\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprecision_warning\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m \u001B[38;5;241m/\u001B[39m std\n\u001B[1;32m   2888\u001B[0m \u001B[38;5;66;03m# If we know that scores and compare are identical, we can infer that\u001B[39;00m\n\u001B[1;32m   2889\u001B[0m \u001B[38;5;66;03m# some slices should have NaNs.\u001B[39;00m\n\u001B[1;32m   2890\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m like_zscore:\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/scipy/stats/_stats_py.py:1128\u001B[0m, in \u001B[0;36m_demean\u001B[0;34m(a, mean, axis, xp, precision_warning)\u001B[0m\n\u001B[1;32m   1121\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_demean\u001B[39m(a, mean, axis, \u001B[38;5;241m*\u001B[39m, xp, precision_warning\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m   1122\u001B[0m     \u001B[38;5;66;03m# subtracts `mean` from `a` and returns the result,\u001B[39;00m\n\u001B[1;32m   1123\u001B[0m     \u001B[38;5;66;03m# warning if there is catastrophic cancellation. `mean`\u001B[39;00m\n\u001B[1;32m   1124\u001B[0m     \u001B[38;5;66;03m# must be the mean of `a` along axis with `keepdims=True`.\u001B[39;00m\n\u001B[1;32m   1125\u001B[0m     \u001B[38;5;66;03m# Used in e.g. `_moment`, `_zscore`, `_xp_var`. See gh-15905.\u001B[39;00m\n\u001B[1;32m   1126\u001B[0m     a_zero_mean \u001B[38;5;241m=\u001B[39m a \u001B[38;5;241m-\u001B[39m mean\n\u001B[0;32m-> 1128\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mxp_size\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma_zero_mean\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m a_zero_mean\n\u001B[1;32m   1131\u001B[0m     eps \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mfinfo(mean\u001B[38;5;241m.\u001B[39mdtype)\u001B[38;5;241m.\u001B[39meps \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m10\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/compare_variance_residual/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:787\u001B[0m, in \u001B[0;36msize\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    784\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[1;32m    785\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\u001B[38;5;241m.\u001B[39mto_device(device, stream\u001B[38;5;241m=\u001B[39mstream)\n\u001B[0;32m--> 787\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21msize\u001B[39m(x):\n\u001B[1;32m    788\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    789\u001B[0m \u001B[38;5;124;03m    Return the total number of elements of x.\u001B[39;00m\n\u001B[1;32m    790\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    795\u001B[0m \n\u001B[1;32m    796\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    797\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m x\u001B[38;5;241m.\u001B[39mshape:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
